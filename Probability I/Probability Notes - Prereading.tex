\documentclass[10pt, a4paper]{article}
\usepackage{preamble}

\declaretheorem[style = avgstyle, name = Counting Principle]{countprinc}

\title{Probability I \\
    \large Prereading}
\author{Luke Phillips}
\date{October 2024}

\begin{document}

\maketitle

\newpage

\section{Introduction}

\subsection{Sets}

A set is an unordered collection of distinguishable objects. 

\begin{definition}[Empty Set]
    The set with no outcomes is called the empty set denoted as $\emptyset$.
    \[
    \emptyset = \{\}
    \]
\end{definition}

\begin{definition}[Subset]
    For two sets $A$ and $B$, $A$ is a subset of $B$, and we write $A \subseteq B$ (or $B \supseteq A$), whenever every element in $A$ also belongs to $B$, for all $x \in A$ we have $x \in B$.
\end{definition}

\begin{example}
    For instance, $\{2, 4, 5\} \subseteq \{1, 2, 3, 4, 5\}$.    
\end{example}

\begin{definition}[Power Set]
    The power set is the set consisting of all subsets of a set $A$, this is denoted as $2 ^ A$\footnote{I have also seen it denoted as $\mathbb{P}(A)$.}.
    \[
    2 ^ A = \{B: B \subseteq A\}.
    \]
\end{definition}

\begin{example}
    The power set of the set $A = \{1, 2, 3\}$ is
    \[
    2 ^ A = \{\emptyset, \{1\}, \{2\}, \{3\}, \{1, 2\}, \{1, 3\}, \{2, 3\}, \{1, 2, 3\}\}.
    \]
\end{example}

\subsection{Sample space and events}
A sample space is a set of all outcomes for this scenario such that one and only one will occur.

The usual notation for a sample space will be $\Omega$, and a generic outcome is $\omega \in \Omega$.

\begin{definition}
    A set $A$ is countable if either:
    \begin{enumerate}[label = (\roman*)]
        \item $A$ is finite, or
        \item there is a bijection (one-to-one and onto mapping) between $A$ and the set of natural numbers $\N$.
    \end{enumerate}
\end{definition}

An even is just a collection of possible outcomes, i.e., a subset of $\Omega$.

\begin{definition}[Events]
    Associated to our sample space $\Omega$ is a collection $\mathcal{F}$ of all events:
    \[
    A \subseteq \Omega \text{ for every } A \in \mathcal{F}.
    \]
    We say that an event $A$ occurs when the outcome that occurs at the end of the scenario is in the set $A$.
\end{definition}

If $\Omega$ is discrete, we can always take $\mathcal{F} = 2 ^ \Omega$, so that every subset of $\Omega$ is an event.

The empty set $\emptyset$ represents the impossible event.

The sample space $\Omega$ represents the certain event, i.e. it will always occur.

\begin{definition}[Complement]
    For an event $A \in \mathcal{F}$, we define its complement, denoted $A ^ c$ (or sometimes $\overline{A}$) and read "not $A$", to be $A ^ c := \Omega \setminus A = \{\omega \in \Omega : \omega \notin A\}$.
\end{definition}

\begin{definition}[Disjoint]
    We say that events $A$ and $B$ are disjoint, mutually exclusive, or incompatible if $A \cap B = \emptyset$, i.e. it is impossible for $A$ and $B$ both to occur.
\end{definition}

We can simplify unions and intersections of multiple sets to being written as:
\[
\bigcup_{i = 1}^{n}{A_i} := A_1 \cup A_2 \cup \dotsi \cup A_n = \{\omega \in \Omega : \omega \in A_i \text{ for at least one } i \in \{1,\dots, n\}\}
\]
and
\[
\bigcap_{i = 1}^{n}{A_i} := A_1 \cap A_2 \cap \dotsi \cap A_n = \{\omega \in \Omega : \omega \in A_i \text{ for every } i \in \{1,\dots, n\}\}.
\]

Occasionally, we will need to take infinite unions and intersections over sequences of sets:
\[
\bigcup_{i = 1}^{\infty}{A_i} := A_1 \cup A_2 \cup A_3 \cup \dotsi = \{\omega \in \Omega : \omega \in A_i \text{ for at least one } i \in \N\}
\]
and
\[
\bigcap_{i = 1}^{\infty}{A_i} := A_1 \cap A_2 \cap A_3 \cap \dotsi = \{\omega \in \Omega : \omega \in A_i \text{ for every } i \in \N\}.
\]

Additionally, we can use De Morgan's Laws for a collection of events $A_i$,
\begin{enumerate}[label = (\alph*)]
    \item $\left(\bigcup_i A_i\right) ^ c = \bigcap_i A_i ^ c$, and
    \item $\left(\bigcap_i A_i\right) ^ c = \bigcup_i A_i ^ c$.
\end{enumerate}

\subsection{The axioms of probability}

\begin{definition}[Probability]
    A probability $\mathbb{P}$ on a sample space $\Omega$ with collection $\mathcal{F}$ of events is a function mapping every event $A \in \mathcal{F}$ to a real number $\mathbb{P}(A)$, obeying the following axioms:
    \begin{enumerate}[label = A\arabic*]
        \item $\mathbb{P}(A) \geq 0$ for every $A \in \mathcal{F}$
        \item $\mathbb{P}(\Omega) = 1$ and
        \item if $A$ and $B$ are disjoint events (i.e. if $A, B \in \mathcal{F}$ have $A \cap B = \emptyset$) then
        \[
        \mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B).
        \]
        We call the number $\mathbb{P}(A)$ the probability of $A$.
        \item Countable additivity. For any infinite sequence $A_1, A_2, \dots$ of pairwise disjoint events (so $A_i \cap A_j = \emptyset$ for all $i \neq j$),
        \[
        \mathbb{P}\left(\bigcup_{i = 1}^{\infty}A_i\right) = \sum_{i = 1}^{\infty}\mathbb{P}(A_i).
        \]
    \end{enumerate}
\end{definition}

\subsection{Consequences of the axioms}
\begin{enumerate}[label = C\arabic*]
    \item For any two events $A$ and $B$,
    \[
    \mathbb{P}(B \setminus A) = \mathbb{P}(B) - \mathbb{P}(A \cap B).
    \]
    \item For any event $A$, $\mathbb{P}(A ^ c) = 1 - \mathbb{P}(A)$.
    \item $\mathbb{P}(\emptyset) = 0$.
    \item For any event $A,\ \mathbb{P}(A) \leq 1$.
    \item Monotonicity. If $A \subseteq B$ then $\mathbb{P}(A) \leq \mathbb{P}(B)$.
    \item For any two events $A$ and $B$,
    \[
    \mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A \cap B).
    \]
    \item Finite additivity. If $A_1, A_2, \dots, A_k$ are pairwise disjoint (so $A_i \cap A_j = \emptyset$ if $i \neq j$) then
    \[
    \mathbb{P}\left(\bigcup_{i = 1}^{k}A_i\right) = \sum_{i = 1}^{k}\mathbb{P}(A_i).
    \]
    \item Boole's inequality. For any events $A_1, A_2, \dots,$ (these need not to be pairwise disjoint),
    \[
    \mathbb{P}\left(\bigcup_{i = 1}^{\infty}A_i\right) \leq \sum_{i = 1}^{\infty}\mathbb{P}(A_i).
    \]
    \item Continuity along monotone limits. If $A_1 \subseteq A_2 \subseteq \dotsi$ is an increasing sequence of events, then
    \[
    \mathbb{P}\left(\bigcup_{n = 1}^{\infty}A_n\right) = \lim_{n \rightarrow \infty}\mathbb{P}(A_n).
    \]
    If $A_1 \supseteq A_2 \supseteq \dotsi$ is an decreasing sequence of events, then
    \[
    \mathbb{P}\left(\bigcap_{n = 1}^{\infty}A_n\right) = \lim_{n \rightarrow \infty}\mathbb{P}(A_n).
    \]
\end{enumerate}

\section{Equally likely outcomes and counting principles}

\subsection{Classical probability}
Suppose we have a finite sample space $\Omega$, $m = |\Omega|$ possible outcomes. In the equally likely outcomes model (also sometimes known as classical probability) we suppose that each outcome has the same probability:
\[
\mathbb{P}(\omega) = \frac{1}{|\Omega|}\text{ for each } \omega \in \Omega,
\]
or, $\mathbb{P}(\omega_i) = \frac{1}{m}$ for each $i$.

Then by the axioms of probability the probability of any event $A \subseteq \Omega$ by C7
\[
\mathbb{P}(A) = \sum_{\omega \in A}\mathbb{P}(\omega) = \frac{|A|}{|\Omega|}\text{ for any event } A \subseteq \Omega.
\]

\begin{definition}[Equally likely outcomes]
    Consider a scenario with $m$ equally likely outcomes enumerated as $\Omega = \{\omega_1,\dots,\omega_m\}$. In the equally likely outcomes model, the probability of an event $A \subseteq \Omega$ is declared to be
    \[
    \mathbb{P}(A) = \frac{|A|}{|\Omega|}
    \]
\end{definition}

\subsection{Counting principles}

\begin{countprinc}[Multiplication principle]
    Suppose that we must make $k$ choices in succession where they are:
    \begin{itemize}
        \item $m_1$ possibilities for the first choice,
        \item $m_2$ possibilities for the second choice, \\
        \vdots
        \item $m_k$ possibilities for the $k$th choice,
    \end{itemize}
    and the number of possibilities at each stage does not depend on the outcomes of any previous choices. The total number of distinct possible selections is
    \[
    m_1 \times m_2 \times m_3 \times \dotsi \times m_k = \prod_{i = 1}^{k}m_i.
    \]
\end{countprinc}

\begin{example}
    PINs are made up of $4$ digits ($0$-$9$) with the exceptions that (i) they cannot be four repetitions of a single digit; (ii) they cannot form increasing or decreasing consecutive sequences, e.g. $3456$ and $8765$ are excluded. How many possible four-digit PINs are there?

    There are a total of $10 ^ 4$ PINs (including the excluded ones). There are $10$ PINs with only repeated digits e.g. $0000,\,1111,\,\dotsc,\,9999$. Additionally, consecutive increasing sequences must begin with $0,\,,1,\,2,\,\dotsc,\,6$, and consecutive decreasing sequences must begin with $9,\,8,\,7,\,\dotsc,\,3$, hence there are $7$ consecutive increasing sequences and $7$ consecutive decreasing sequences. Therefore, $10 + 7 + 7 = 24$ PINs are excluded from the $10 ^ 4$ total PINs. There are $10 ^ 4 - 24$ possible PINs. 
\end{example}

\begin{countprinc}[Ordered choices of distinct objects with replacement]
    Suppose that we have a collection of $m$ distinct objects and we select $r$ of them with replacement. The number of different ordered lists (ordered $r$-tuples) is
    \[
    \underbrace{m \times \dotsi \times m}_{r \text{ times}} = m ^ r
    \]
\end{countprinc}

\begin{countprinc}[Ordered choices of distinct objects without replacement]
    Suppose that we have a collection of $m$ distinct objects and we select $r \leq m$ of them without replacement. The number of different ordered lists (ordered $r$-tuples) is
    \[
    (m)_r := \underbrace{m \times (m - 1) \times (m - 2) \times \dotsi \times (m - r + 1)}_{r \text{ terms}} = \frac{m!}{(m - r)!}.
    \]
\end{countprinc}
So, the falling factorial notation $(m)_r$ (sometimes also denoted $m ^ {\underline{r}}$ is simply a convenient way to write $\frac{m!}{(m - r)!}$. In the case where $r = m$ we set $0! = 1$ and then $(m)_m = m!$ is the number of permutations of the $m$ objects. If $m$ is large, and $r$ is much smaller than $m$, then $(m)_r \approx m ^ r$.

\begin{example}[Birthday problem]
    There are $n < 365$ people in a room. Let $B$ be the event that (at least) two of them have the same birthday. (We ignore leap years.) What is $\mathbb{P}(B)$? How big must $n$ be so that $\mathbb{P}(B) > \frac{1}{2}$?

    The number of possible outcomes is
    \[
    365 \times 365 \times \dotsi \times 365 = 365 ^ n.
    \]
    This is the denominator of the probability. For the numerator, we must work out how many outcomes there are in $B$. In order to do this it is easier to count the number of outcomes in $B ^ c$, where everyone has a different birthday. The number of outcomes in $B ^ c$ is
    \[
    365 \times 364 \times \dotsi \times (365 - n + 1) = (365)_n.
    \]
    So
    \[
    \mathbb{P}(B) = 1 - \mathbb{P}(B ^ c) = 1 - \frac{(365)_n}{365 ^ n}.
    \]

    To find for what $n$ $\mathbb{P}(B) > \frac{1}{2}$ we can consider the following,
    \[
    \frac{(365)_n}{365 ^ n} = 1 \times \left(1 - \frac{1}{365}\right) \times \left(1 - \frac{2}{365}\right) \times \dotsi \times \left(1 - \frac{n - 1}{365}\right).
    \]
    For this we can see that $1 - x \leq e ^ {-x}$, in fact this is close to equality for $x = \frac{1}{365}$\footnote{Since $e^{-x}$ shrinks so rapidly and $\frac{1}{365}$ is already quite close to $0$.}, being close to zero.
    \begin{align*}
        \frac{(365)_n}{365 ^ n} &\leq e ^ {-x} e ^ {-2x} e ^ {-3x} \dotsi e^{-(n - 1)x} \\
        &= \exp{-(1 + 2 + \dotsi + n - 1)x} \\
        &= \exp{-\frac{(n - 1)n}{2 \times 365}}.
    \end{align*}
\end{example}

\begin{countprinc}[Unordered choices of distinct objects without replacement]
    Suppose that we have a collection of $m$ distinct objects and we select a subset of $r \leq m$ of them without replacement. The number of distinct subsets of size $r$ is
    \[
    \binom{m}{r} := \frac{(m)_r}{r!} = \frac{m!}{r!(m - r)!}.
    \]
\end{countprinc}

The expression $\binom{m}{r}$ is the binomial coefficient for choosing $r$ objects from $m$ and is often called $m$-choose-$r$. Note that
\[
\binom{m}{r} = \binom{m}{m - r}
\]

\begin{example}
    What is the probability of finding no aces in a four-card hand dealt from a well-shuffled deck?

    There are $52$ cards in a deck and $4$ aces in a deck. To choose $4$ cards from a deck there are $\binom{52}{4}$ ways of doing this. Now, assume that we have taken all of the aces out of the deck, then there are $\binom{48}{4}$ ways of choosing $4$ cards which are not aces. Finding the probability of choosing a hand with aces we can see that it is the number of chooses without the aces compared to the chooses with aces, i.e.
    \[
    \frac{\binom{48}{4}}{\binom{52}{4}} = \frac{(48)_4}{(52)_4}.
    \]
    This is approximately $0.7$.
\end{example}

\begin{countprinc}[Ordered choices of $2$ types of objects]
    Suppose that we have $m$ objects, $r$ of type $1$ and $m - r$ of type $2$, where objects are indistinguishable from others of their type. The number of distinct, ordered choices of the $m$ objects is
    \[
    \binom{m}{r}.
    \]
\end{countprinc}

\begin{countprinc}[Ordered grouping of indistinguishable objects]
    The number of ways to divide $m$ indistinguishable objects into $k$ distinct groups is
    \[
    \binom{m + k - 1}{m} = \binom{m + k - 1}{k - 1}.
    \]
\end{countprinc}

\begin{example}
    How many ways are there to divide $6$ (identical) pound coins amongst $3$ (distinguished) people?

    There are $\binom{6 - 3 - 1}{6} = \binom{8}{2} = 28$ ways to divide the coins amongst the people.
\end{example}


\end{document}