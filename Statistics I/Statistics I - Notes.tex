\documentclass[10pt, a4paper]{article}
\usepackage{preamble}


\title{Statistics I}
\author{Luke Phillips}
\date{January 2025}

\begin{document}

\maketitle

\newpage

\tableofcontents

\newpage

\section{}

\subsection{High Profile Applications}
\textbf{Useless films}.

\subsection{What is Statistics?}
Statistics involves the mathematical representation of key real world quantities of interest and their associated uncertainties
(often,
but not always using probability),
the coherent incorporation of any
(uncertain)
knowledge,
information or observed data into this framework and the subsequent learning,
prediction,
future experimental design and decision making in the presence of uncertainty that this structure facilitates.

\subsection{Frequentists and Bayesian Statistics}
Bayesian statistics requires more input.

The relative frequency interpretation of probability is linked to frequentist statistics.

The subjective interpretation of probability is linked to frequentist Bayesian statistics.

\textit{Genuine waffle for about half an hour}.

\begin{example}[Motivating example 1 - Covid-19 Disease Test]
    A new test for Covid-19 has been developed.
    It is fast and cheap,
    but has moderate accuracy.
    It has been tested on a limited set of people with known Covid status.
    
    You are selected at random from the UK population in August $2020$ and you test positive.
    What is the probability you have Covid?
    How about if you were selected from the London population in January $2021$.
\end{example}

\begin{example}[Motivating example 2 - US Presidential Election polling]
    $22$nd of October $2024$,
    two weeks before the $2024$ US presidential election.
    You run a polling company and you have conducted a poll of $1000$ people form Pennsylvania state.
    Out of $1000$ people:
    $485$ said they'd vote for Harris,
    $515$ said they'd vote for Trump.
    Everyone wants to know your prediction.
\end{example}

\subsection{Foundations of Statistics and Interpretation of Probability}

\subsubsection{Probability: Revision}

\begin{definition}[Axioms of Probability]
    For a sample space $\Omega$,
    with collection $\mathcal{F}$ of events,
    the probability $\P(A)$ satisfies the axioms:
    \begin{enumerate}[label = A\arabic*]
        \item $\P(A) \geq 0$,
        for every $A \in \mathcal{F}$.

        \item $\P(\Omega) = 1$.

        \item For $A$ and $B$ disjoint then:
        \[
        \P(A \cup B) = \P(A) + \P(B)
        \]
    \end{enumerate}
\end{definition}

The axioms lead to some of the following consequences
\begin{proposition}
    \begin{enumerate}[label = (\roman*)]
        \item $0 \leq \P(A) \leq 1$.
        
        \item $\P(A ^ c) = 1 - \P(A)$.
        
        \item $\P(\emptyset) = 0$.
    \end{enumerate}
\end{proposition}

\subsubsection{Interpretations of Probability}
\textbf{Classical}

This is based on an assumption underlying equally likely events.

\textbf{Frequentist}

An event $A$ has probability $\P(A)$ given by:
\[
\P(A) = \liminfty\frac{n_A}{n},
\]
where $n_A$ is the number of times event $A$ occurred in $n$ repetitions of the experiment.

\textbf{Subjective}

Probabilities are viewed as subjective about the likelihood of an event $A$ occurring.
This can be defined in a precise way and Probability Axioms are actually derived as requirements of coherence.

\subsubsection{A Summary of Useful Probability Results}
\underline{Combining Events}

The event $A, B$ or both occur is $A \cup B$.
The event $A$ and $B$ occur is $A \cap B$.
These are related by the following rule
\[
\P(A \cup B) = \P(A) + \P(B) - \P(A \cap B).
\]
Events are disjoint if they cannot occur at the same time.

Addition law for disjoint events:
If $A$ and $B$ are disjoint events
\[
\P(A \cup B) = \P(A) + \P(B).
\]

\underline{Conditional Probability and Independence}

For any two events $A, B$,
the notation $\P(A | B)$ means the conditional probability that $A$ occurs,
assuming that the event $B$ has already occurred.

Conditional probability is obtained directly or by using the conditional probability rule:
\[
\P(A | B) = \frac{\P(A | B)}{\P(B)},
\]
for $\P(B) > 0$.

Rearranging we get the general multiplication rule
\[
\P(A | B) = \P(A | B)\P(B).
\]

Two events are independent when the occurrence of one has no bearing on the occurrence of the other.
If $A, B$ are independent then
\[
\P(A | B) = \P(A).
\]

\underline{Partitions}

Suppose $E_1, \dotsc, E_n$ are mutually disjoint events,
and suppose exactly one must happen.
Such a collection of events is called a
(sure)
partition.

We can write any other event $A$ in combination with this event:
in general,
\[
\P(A) = \P(A \cap E_1) + \P(A \cap E_2) + \dotsc + \P(A \cap E_n),
\]
which simplifies to
\[
\P(A) = \P(A | E_1)\P(E_1) + \dotsc + \P(A | E_n)\P(E_n)
\]
using the multiplication rule.

\underline{Bayes Theorem}

For any two events $A, B$,
the multiplication rule gives the formula
\[
\P(A \cap B) = \P(A | B)\P(B).
\]
Another equivalent formula is obviously
\[
\P(A \cap B) = \P(B | A)\P(A).
\]

Equating these we get the formula known as Bayes theorem:
\[
\P(A | B) = \frac{\P(B | A)\P(A)}{\P(B)}.
\]
Often the probability in the denominator must be calculated using the simplifying method shown in the last section;
i.e. via a partition.

\newpage

\section{Disease Testing using Bayesian Methods}

\subsection{Testing for Covid-19}

Remember motivating example $1$.
\begin{enumerate}[label = (\roman*)]
    \item 
    We have data from a limited sample of $620$ patients given the new test is the 'gold standard'
    (i.e. perfect).

    Events
    \begin{align*}
        D ^ {+} &= \text{person has disease}. \\
        D ^ {-} &= \text{person doesn't have disease}. \\
        T ^ {+} &= \text{person tests positive}. \\
        T ^ {-} &= \text{person tests negative}.
    \end{align*}
    \begin{table}[H]
        \begin{tabular}{c|c|c|c}
             & Yes $D ^ {+}$ & No $D ^ {-}$ & Total \\
             \hline
             Test result positive $T ^ {+}$ & $209$ & $6$ & $215$ \\
             Test result negative $T ^ {-}$ & $11$ & $394$ & $405$ \\
             \hline
             Total & $220$ & $400$ & $620$
        \end{tabular}
    \end{table}

    Probability distribution
    \begin{align*}
        \P_t &= \text{probability distribution for test group of $620$ people}. \\
        \P &= \text{probability distribution of general UK population}.
    \end{align*}

    Probabilities of interest
    \begin{align*}
        \P_t\left(T ^ {+} \mmid D ^ {+}\right) &= \text{sensitivity of the test} \\
        \P_t\left(T ^ {-} \mmid D ^ {-}\right) &= \text{specificity of the test} \\
        \P_t\left(T ^ {+} \mmid D ^ {-}\right) &= \text{probability of a false positive} \\
        \P_t\left(T ^ {-} \mmid D ^ {+}\right) &= \text{probability of a false negative}
    \end{align*}

    Sensitivity:
    \begin{align*}
        \P_t\left(T ^ {+} \mmid D ^ {+}\right) &= \frac{\P_t(T ^ {+} \cap D ^ {+})}{\P_t(D ^ {+})} \\
        &= \frac{\frac{209}{620}}{\frac{270}{620}} \\
        &= \frac{209}{270} \\
        &= 0.95.
    \end{align*}

    Specificity:
    \begin{align*}
        \P_t\left(T ^ {-} \mmid D ^ {-}\right) &= \frac{\P_t(T ^ {-} \cap D ^ {-})}{\P_t(D ^ {-}} \\
        &= \frac{\frac{396}{620}}{\frac{400}{620}} \\
        &= \frac{396}{400} \\
        &= 0.8985.
    \end{align*}

    False positive:
    \begin{align*}
        \P_t\left(T ^ {+} \mmid D ^ {-}\right) &= 1 - \P_t\left(T ^ {-} \mmid D ^ {-}\right) \\
        &= 1 - 0.8985 \\
        &= 0.015.
    \end{align*}

    False negative:
    \begin{align*}
        \P_t\left(T ^ {-} \mmid D ^ {+}\right) &= 1 - \P_t\left(T ^ {+} \mmid D ^ {+}\right) \\
        &= 1 - 0.95 \\
        &= 0.05.
    \end{align*}

    Question:

    We care about the whole U.K. population.
    How does it relate to our test set?

    Assumption

    The sensitivity and specificity are a property of the test only.

    Hence
    \begin{align*}
        \P\left(T ^ {+} \mmid D ^ {+}\right) &= \P_t\left(T ^ {+} \mmid D ^ {+}\right). \\
        \P\left(T ^ {-} \mmid D ^ {-}\right) &= \P_t\left(T ^ {-} \mmid D ^ {-}\right). \\
        \P\left(T ^ {+} \mmid D ^ {-}\right) &= \P_t\left(T ^ {+} \mmid D ^ {-}\right). \\
        \P\left(T ^ {-} \mmid D ^ {+}\right) &= \P_t\left(T ^ {-} \mmid D ^ {+}\right).
    \end{align*}
    This is not true for other probabilities such as $\P(D ^ {+}) \neq \P_t(D ^ {+})$.
\end{enumerate}

\subsection{Bayesian Inference: from prior to posterior}
\begin{definition}
    Prior,
    likelihood,
    posterior.
    \[
    \P(D ^ {+}) = \text{prior probability of having Covid-19.\footnotemark}
    \]
    \footnotetext{Prevalence in the relevant population.}
    \[
    \P\left(T ^ {+} \mmid D ^ {+}\right), \P\left(T ^ {+} \mmid D ^ {-}\right) = \text{likelihood of positive test given disease states.}
    \]
    \[
    \P\left(D ^ {+} \mmid T ^ {+}\right) = \text{posterior probability of having Covid-19 given a positive test.}
    \]
    The posterior is critical and found using Bayes Theorem:
    \begin{align*}
        \P\left(D ^ {+} \mmid T ^ {+}\right) &= \frac{\P\left(T ^ {+} \mmid D ^ {+}\right)\P\left(D ^ {+}\right)}{\P\left(T ^ {+}\right)} \quad\text{(by Bayes theorem)} \\
        &= \frac{\P\left(T ^ {+} \mmid D ^ {+}\right)\P\left(D ^ {+}\right)}{\P\left(T ^ {+} \mmid D ^ {+}\right)\P\left(D ^ {+}\right) + \P\left(T ^ {+} \mmid D ^ {-}\right)\P\left(D ^ {-}\right)} \quad\text{(by partition)}\\
        &= \frac{\P_t\left(T ^ {+} \mmid D ^ {+}\right)\P\left(D ^ {+}\right)}{\P_t\left(T ^ {+} \mmid D ^ {+}\right)\P\left(D ^ {+}\right) + \P_t\left(T ^ {+} \mmid D ^ {-}\right)\P\left(D ^ {-}\right)} \quad\text{(by assumptions)} \\
    \end{align*}
    Covid-19 Example:
    August $2020$ U.K.

    In August $2020$ U.K. it was thought that $0.00025$ of the U.K. population had Covid-19.
    \[
    \P(D ^ {+}) = 0.00025
    \]
    and
    \[
    \P(D ^ {-}) = 1 - \P(D ^ {+})
    \]
    \begin{align*}
        \P\left(D ^ {+} \mmid T ^ {+}\right) &= \frac{\P\left(T ^ {+} \mmid D ^ {+}\right)\P\left(D ^ {+}\right)}{\P\left(T ^ {+}\right)} \\
        &= \frac{\P\left(T ^ {+} \mmid D ^ {+}\right)\P\left(D ^ {+}\right)}{\P\left(T ^ {+} \mmid D ^ {+}\right)\P\left(D ^ {+}\right) + \P\left(T ^ {+} \mmid D ^ {-}\right)\P\left(D ^ {-}\right)} \\
        &= \frac{0.95 \times 0.00025}{0.95 \times 0.00025 + 0.015 \times (1 - 0.00025)} \\
        &= \frac{0.0002375}{0.0002375 + 0.01499625} \\
        &= 0.0156.
    \end{align*}
\end{definition}

Why is the posterior probability $\P\left(D ^ {+} \mmid T ^ {+}\right)$ still so low?

Because our prior probability $\P(D ^ {+}) = 0.00025$ was so low,
that although the evidence from $T ^ {+}$ increases our probability,
it still ends up as relatively small.

Another way to see this is if we examine the denominator of Bayes Theorem which gives us the probability of a positive test result $T ^ {+}$.
We can see that a positive test comes from either you had the disease or you did not,
hence
\begin{align*}
    \P(T ^ {+}) &= \P\left(T ^ {+} \mmid D ^ {+}\right)\P(D ^ {+}) + \P\left(T ^ {+} \mmid D ^ {-}\right)\P(D ^ {-}) \\
    &= 0.0002375 + 0.01499625.
\end{align*}
We can see that the contribution from having the disease is much smaller than the contribution of having a false positive.

\textbf{Covid-19 Test Example:}
Applying Bayes Theorem
(London January $2021$ case)

If the above discussion is correct,
we should see a different result for our second question:
\begin{center}
    \textit{If instead you were selected at random from the London population in January $2021$
    (and you test positive),
    what is the probability
    (that you have Covid-19)
    then?}
\end{center}

It was thought,
in early January $2021$ that $0.03$ of the London population had Covid-19.

We can similarly apply Bayes theorem but now using the much larger prior probability of $\P(D ^ {+}) = 0.03$,
this yields:
\begin{align*}
    \P\left(D ^ {+} \mmid T ^ {+}\right) &= \frac{\P\left(T ^ {+} \mmid D ^ {+}\right)\P(D ^ {+})}{\P(T ^ {+})} \\
    &= \frac{0.95 \cdot 0.03}{\P(T ^ {+})} \\
    &= \frac{0.95 \cdot 0.03}{\P\left(T ^ {+} \mmid D ^ {+}\right)\P(D ^ {+}) + \P\left(T ^ {+} \mmid D ^ {-}\right)\P(D ^ {-})} \\
    &= \frac{0.95 \cdot 0.03}{0.95 \cdot 0.03 + 0.015 \cdot (1 - 0.03)} \\
    &= \frac{0.0285}{0.0285 + 0.01455} \\
    &= 0.662.
\end{align*}
So given a positive result,
you now have a $66.2\%$ chance of having Covid-19,
this is much higher.

Note that the route of having the disease contributes a lot more to the denominator of Bayes theorem than the route of not having the disease.

\subsection{More Advanced Bayesian Calculations}

\subsubsection{Performing Further Tests}
Consider the August $2020$ UK example above.
If you had tested positive you still only had a $1.56\%$ chance of having Covid-19.

Naturally,
you would take the test again.
You do this and receive a second positive test,
what is your probability now?

We denote two positive tests as $T ^ {++}$,
but now we have to consider the nature of the test further.

A possible assumption is that the test results are conditionally independent given disease status,
implying that
\[
\P\left(T ^ {++} \mmid D ^ {+}\right) = \P\left(T ^ {+} \mmid D ^ {+}\right) ^ 2\qquad\text{and}\qquad\P\left(T ^ {++} \mmid D ^ {-}\right) = \P\left(T ^ {+} \mmid D ^ {-}\right) ^ 2.
\]
This might be reasonable if the test fails independently each time,
i.e. due to reasons entirely unrelated to the specific attributes of the patient.

The other extreme is that the test fails precisely due to the specifics of the patient,
and will fail the same way again and again,
leading to $\P\left(T ^ {++} \mmid D ^ {+}\right) = \P\left(T ^ {+}\mmid D ^ {+}\right)$ etc.

\begin{example}[Covid-19 Test Example: Two Positive Test Results]
    We are again in August $2020$ UK and assume the same prior as before:
    $\P(D ^ {+}) = 0.00025$.

    But now we want the probability of Covid-19 given two positive test results $T ^ {++}$:
    \begin{align*}
        \P\left(D ^ {+} \mmid T ^ {++}\right) &= \frac{\P\left(T ^ {++} \mmid D ^ {+}\right)\P(D ^ {+})}{\P(T ^ {++})} \\
        &= \frac{\P\left(T ^ {+} \mmid D ^ {+}\right) ^ 2 \cdot 0.0025}{\P\left(T ^ {++} \mmid D ^ {+}\right)\P(D ^ {+}) + \P\left(T ^ {++} \mmid D ^ {-}\right)\P(D ^ {-})} \\
        &= \frac{\P\left(T ^ {+} \mmid D ^ {+}\right) ^ 2 \cdot 0.0025}{\P\left(T ^ {+} \mmid D ^ {+}\right) ^ 2\P(D ^ {+}) + \P\left(T ^ {+} \mmid D ^ {-}\right) ^ 2\P(D ^ {-})} \\
        &= \frac{0.95 ^ 2 \cdot 0.0025}{0.95 ^ 2 \cdot 0.00025 + (0.015) ^ 2 \cdot (1 - 0.00025)} \\
        &= 0.501.
    \end{align*}
    Under the conditional independence assumption,
    your posterior probability after two tests is now $50.1\%$:
    much higher than the $1.56\%$ from a single positive test.
\end{example}

\subsubsection{A Model for Sequential Learning}

Sequential learning occurs when we do two tests in a row.
Receiving one positive result,
then a second we had:
\begin{align*}
    \P(D ^ {+}) &\rightarrow \P\left(D ^ {+} \mmid T ^ {+}\right) &\rightarrow \P\left(D ^ {+} \mmid T ^ {++}\right) \\
    0.00025 &\rightarrow 0.0156 &\rightarrow 0.501
\end{align*}
that is,
as more information comes in,
we update our beliefs about the probability of $D ^ {+}$ again and again.

When we calculated the two test result we actually went straight from
\begin{align*}
    \P(D ^ {+}) &\rightarrow \P\left(D ^ {+} \mmid T ^ {++}\right) \\
    0.00025 &\rightarrow 0.501.
\end{align*}
Bayes theorem is consistent in the sense that we can update sequentially by one $T ^ {+}$ then by another $T ^ {+}$,
or all at once
(i.e. by $T ^ {++}$)
and we are guaranteed to obtain the same result.

\begin{example}
    Label the first positive test as $T_1 ^ {+}$
    (occurring on day $1$)
    and the second test as $T_2 ^ {+}$
    (occurring on day $2$).
    If,
    after seeing a single positive result $T_1 ^ {+}$ we updated to get posterior $\P\left(D ^ {+} \mmid T_1 ^ {+}\right)$ and trivially also $\P\left(D ^ {-} \mmid T_1 ^ {+}\right)$,
    then we could treat these posteriors as our priors for day $2$.
    Hence on day $2$ we could update using the second positive test $T_2 ^ {+}$ using Bayes theorem
    (with $T ^ {++} = \{T_1 ^ {+}, T_2 ^ {+}\}$):
    \begin{align*}
        \P\left(D ^ {+} \mmid T ^ {++}\right) = \P\left(D ^ {+} \mmid T_1 ^ {+}, T_2 ^ {+}\right) &= \frac{\P\left(T_2 ^ {+} \mmid D ^ {+}, T_1 ^ {+}\right)\P\left(D ^ {+} \mmid T_1 ^ {+}\right)}{\P\left(D ^ {+} \mmid T_2 ^ {+}\right)} \\
        &= \frac{\P\left(T_2 ^ {+} \mmid D ^ {+}, T_1 ^ {+}\right)\P\left(D ^ {+} \mmid T_1 ^ {+}\right)}{\P\left(T_2 ^ {+} \mmid D ^ {+}, T_1 ^ {+}\right)\P\left(D ^ {+} \mmid T_1 ^ {+}\right) + \P\left(T_2 ^ {+} \mmid D ^ {-}, T_1 ^ {+}\right)\P\left(D ^ {-} \mmid T_1 ^ {+}\right)} \\
        &= \frac{\P\left(T_2 ^ {+} \mmid D ^ {+}, T_1 ^ {+}\right)\P\left(D ^ {+} \mmid T_1 ^ {+}\right)}{\P\left(T_2 ^ {+} \mmid D ^ {+}\right)\P\left(D ^ {+} \mmid T_1 ^ {+}\right) + \P\left(T_2 ^ {+} \mmid D ^ {-}\right)\P\left(D ^ {-} \mmid T_1 ^ {+}\right)}
    \end{align*}
    where we have used the conditional independence assumption to simplify terms such as $\P\left(T_2 ^ {+} \mmid D ^ {+}, T_1 ^ {+}\right) = \P\left(T_2 ^ {+} \mmid D ^ {+}\right)$.
\end{example}

\subsubsection{Sensitivity of the Posterior \texorpdfstring{$\P\left(D ^ {+} \mmid T ^ {+}\right)$}{} to the Sensitivity and Specificity}

We can perform a simple sensitivity analysis by examining the derivative of the posterior with respect to the sensitivity and the specificity,
keeping all other things constant when performing the derivative.
\[
\text{Sensitivity:}\quad\frac{d\P\left(D ^ {+} \mmid T ^ {+}\right)}{d\P\left(T ^ {+} \mmid D ^ {+}\right)}\qquad\text{Specificity:}\quad\frac{d\P\left(D ^ {+} \mmid T ^ {+}\right)}{d\P\left(T ^ {-} \mmid D ^ {-}\right)}
\]
For example,
denoting the specificity as $x = \P\left(T ^ {-} \mmid D ^ {-}\right)$,
then we have
\begin{align*}
    \P\left(D ^ {+} \mmid T ^ {+}\right) &= \frac{\cP{T ^ {+}}{D ^ {+}}\P(D ^ {+})}{\cP{T ^ {+}}{D ^ {+}}\P(D ^ {+}) + (1 - x)\P(D ^ {-})} \\
    \frac{d\P\left(D ^ {+} \mmid T ^ {+}\right)}{d\P\left(T ^ {-} \mmid D ^ {-}\right)} = \frac{d}{dx}\cP{D ^ {+}}{T ^ {+}} &= \frac{\cP{T ^ {+}}{D ^ {+}}\P(D ^ {+})\P(D ^ {-})}{[\cP{T ^ {+}}{D ^ {+}}\P(D ^ {+}) + (1 - x)\P(D ^ {-})] ^ 2}.
\end{align*}

\subsubsection{Odds and the Likelihood Ratio}
\begin{definition}[Prior and posterior odds and the likelihood ratio]
    Prior odds in favour of $A = \frac{\P(A)}{\P(A ^ c)}$.

    Posterior odds in favour of $A$ given $B = \frac{\cP{A}{B}}{\cP{A ^ c}{B}}$.

    Likelihood ratio for $B$ given $A = \frac{\cP{B}{A}}{\cP{B}{A ^ c}}$.

    It is simple to show that
    \[
    \text{posterior odds} = \text{prior odds} \times \text{likelihood ratio}.
    \]
\end{definition}

The likelihood ratio can be interpreted as a factor which determines whether the posterior odds are smaller
(likelihood ratio $< 1$)
or larger
(likelihood ratio $> 1$)
than the prior odds,
and by how much.

\newpage

\section{US Presidential Election Polling via Frequentist Methods}

\subsection{Random Variables,
Expectation and Variance:
Revision and Notation}

\subsubsection{Discrete Random Variables}
A discrete random variable $X$ is a variable which can take a finite set of different numerical values $x_1, x_2, \dotsc, \in \mathcal{X}$.

The probability mass function is
\[
f(x) = \P(X = x),\qquad\forall x \in \mathcal{X}.
\]

Given
\[
f\left(x \mmid \lambda\right) = \P(X = x) = \begin{cases}
    \frac{e ^ {-\lambda}\lambda ^ x}{x!} & \text{for } x = 0, 1, 2, \dotsc \\
    0 & \text{otherwise}.
\end{cases}
\]
We write $f\left(x \mmid \lambda\right)$ for the $f$ of $x$ given $\lambda$.

\subsubsection{Expectation and Variance of a Discrete Random Variable}
The expected value of a discrete random variable $X$ is defined as
\[
\E(X) = \sum_{x \in \mathcal{X}}x\P(X = x) = \sum_{x \in \mathcal{X}}xf(x)
\]
that is,
we take a weighted average of $X$.

The expected value of any function $h(X)$ of $X$ is defined to be
\[
\E(h(X)) = \sum_{x \in \mathcal{X}}h(x)\P(X = x) = \sum_{x \in X}h(x)f(x).
\]

The variance of $X$ is defined to be
\begin{align*}
    \Var(X) &= \E((X - \E(X)) ^ 2) \\
    &= \E(X ^ 2) - \E(X) ^ 2.
\end{align*}
This measures the theoretical average of the distance of the values of the random variable $X$ from its central value as measured by the expected value.
$\Var(X)$ measures the spread of values of a random variable.

The standard deviation of a random variable is just the square root of the variance
\[
\mathrm{SD}(X) = \sqrt{\Var(X)}.
\]

\subsubsection{Continuous Random Variables}
The probability density function $f$ of a continuous random variable $X$ describes the probability density of each value,
defined as follows
\begin{align*}
    \P(x \leq X \leq x + dx) &= f(x)\,dx \\
    \P(a \leq X \leq b) &= \int_{a}^{b}f(x)\,dx.
\end{align*}

\subsubsection{Expectation and Variance of a Continuous Random Variable}
The expectation,
variance and standard deviation of a continuous random variable $X$ with probability density function $f(x)$ are:
\begin{align*}
    \E(X) &= \int xf(x)\,dx \\
    \Var(X) &= \E((X - \E(X)) ^ 2) \\
    &= \E(X ^ 2) - (\E(X)) ^ 2 &\left(\text{with } \E(X ^ 2) = \int x ^ 2f(x)\,dx\right) \\
    \mathrm{SD}(X) = \sqrt{\Var(X)}
\end{align*}
where integration is over the full range of values of $X$.

\subsubsection{Properties of Expectations and Variances}
\textbf{Change in scale and location}

For any random variable $X$ and any two real numbers $a, b$.
\begin{align*}
    \E(aX + b) &= a\E(X) + b \\
    \Var(aX + b) &= a ^ 2\Var(X) \\
    \mathrm{SD}(aX + b) &= a\mathrm{SD}(X).
\end{align*}

\textbf{Sums and differences}

For any two random variables $X, Y$ and any two real numbers $a, b$.
\begin{align*}
    \E(aX + bY) &= a\E(X) + b\E(Y). \\
    \intertext{If $X$ and $Y$ are independent} \\
    \Var(aX + bY) &= a ^ 2\Var(X) + b ^ 2\Var(Y). \\
    \intertext{If $X$ and $Y$ are not independent} \\
    \Var(aX + bY) &= a ^ 2\Var(X) + b ^ 2\Var(Y) + 2ab\Cov(X, Y).
\end{align*}
These rules can be extended to sums of several random variables.

Consider any $n$ random variables $X_1, X_2, \dotsc, X_n$ then
\[
\E(X_1 + X_2 + \dotsi + X_n) = \E(X_1) + \E(X_2) + \dotsi + \E(X_n)
\]
additionally if all $X_i$ are independent of each other then
\[
\Var(X_1 + X_2 + \dotsi + X_n) = \Var(X_1) + \Var(X_2) + \dotsi + \Var(X_n).
\]

\subsection{Random Sampling,
Proportions and the Bernoulli Distribution}

\subsubsection{The Bernoulli Distribution}

For an experiment where there are only two possible outcomes,
and we can designate the two possible outcomes as $0$ or $1$,
we can apply the following definition.
\begin{definition}[Bernoulli Distribution]
    We say that a random variable $X$ has a Bernoulli distribution with parameter $p$ with
    ($0 \leq p \leq 1$)
    if $X$ can take only the values $0$ and $1$ with respective probabilities
    \begin{align*}
        \P(X = 1) = p&&\text{and}&&\P(X = 0) = 1 - p
    \end{align*}
    setting $q = 1 - p$ we can write the pmf as
    \[
    f\left(x \mmid p\right) = \begin{cases}
        p ^ xq ^ {1 - x} &\text{for } x = 0, 1, \\
        0 &\text{otherwise}.
    \end{cases}
    \]
    To see that $f\left(x \mmid p\right)$ represents the Bernoulli distribution as given by the probabilities we can just note that
    \begin{align*}
        f\left(1 \mmid p\right) = p &&\text{and}&&f\left(0 \mmid p\right) = q.
    \end{align*}
\end{definition}

If $X$ has a Bernoulli distribution with parameter $p$ then we can directly calculate its expectation and variance:
\begin{align*}
    \E(X) &= \sum_{x \in X}xf\left(x \mmid p\right) = p \\
    \E(X ^ 2) &= \sum_{x \in X}x ^ 2f\left(x \mmid p\right) = p \\
    \intertext{Hence the variance is given by} \\
    \Var(X) &= \E(X ^ 2) - \E(X) ^ 2 = pq.
\end{align*}

Furthermore,
we can calculate the moment generating function as
\[
\psi(t) = \E(e ^ {tX}) = \sum_{x \in X}e ^ {tx}f\left(x \mmid p\right) = q + pe ^ t\qquad\text{for } -\infty < t < \infty.
\]

\subsubsection{Bernoulli Trials}
If we have a sequence of $n$ random variables $X_1, \dotsc, X_n$ which are independent and identically distributed and if each of the $X_i$ has a Bernoulli distribution with parameter $p$ then we say that the variables $X_1, \dotsc, X_n$ form $n$ Bernoulli trials with parameter $p$.

\subsubsection{Statistical Inference}
If we view $p$ as real,
fixed with a "true" value that is just unknown,
we may seek to construct from the data $X_1, \dotsc, X_n$ some way of giving an estimate of $p$,
and then subsequently examining the attributes of this estimator.

We can also view $p$ as an unknown quantity for which we should represent our subjective uncertainty about via a probability distribution.
Then we can do somewhat similar as what we did with treating it as a fixed "true" value.

\subsubsection{Total and sample proportions as estimators}
Let us redefine the random quantity $X$ to be the sum of all successes over the $n$ trials,
\begin{align*}
    X = \sum_{i = 1}^{n}X_i&&\text{with } X_i = \begin{dcases*}
        1 & when $i$ is a success \\
        0 & when $i$ is a failure.
    \end{dcases*}
\end{align*}

To guide us in estimating $p$,
it is worth noting what the pmf is for a set of Bernoulli trials $X_1, \dotsc, X_n$:
as the $X_i$ are independent we can then just multiply the individual pmfs.
Therefore
\begin{align*}
    f\left(x_1, x_2, \dotsc, x_n \mmid p\right) &= \prod_{i = 1}^{n}f\left(x_i \mmid p\right) \\
    &= \prod_{i = 1}^{n}p ^ {x_i}q ^ {1 - x_i} \\
    &= p ^ {\sum_{i = 1}^{n}x_i}q ^ {\sum_{i = 1}^{n}(1 - x_i)} \\
    &= p ^ xq ^ {n - x}
\end{align*}
where we have denoted $x = \sum_{i = 1}^{n}x_i$ the sum of the successes.

We can see that the pmf only relies on the probability $p$,
the total number of Bernoulli trials $n$ and the number of successes $x$.

To get a good estimator we could ask what value of $p$ will maximise the pmf $f\left(x_1, \dotsc, x_n \mmid p\right)$?
To maximise $f\left(x_1, \dotsc, x_n \mmid p\right)$ we can maximise the $\log$ of $f\left(x_1, \dotsc, x_n \mmid p\right)$ as this is easier to differentiate
\begin{align*}
    f\left(x_1, \dotsc, x_n \mmid p\right) &= p ^ xq ^ {n - x} \\
    \implies \log{f\left(x_1, \dotsc, x_n \mmid p\right)} &= x\log{p} + (n - x)\log{q} \\
    \implies \pd{p}\log{f\left(x_1, \dotsc, x_n \mmid p\right)} &= \frac{x}{p} - \frac{n - x}{1 - p}
\end{align*}
therefore an estimate for $p$,
which we will denote $\hat{p}$,
which maximises $f\left(x_1, \dotsc, x_n \mmid p\right)$ is given by
\begin{align*}
    \frac{x}{\hat{p}} - \frac{n - x}{1 - \hat{p}} &= 0 \\
    \implies x(1 - \hat{p}) &= (n - x)\hat{p} \\
    \implies x - x\hat{p} &= n\hat{p} - x\hat{p} \\
    \implies x &= n\hat{p} \\
    \implies \hat{p} &= \frac{x}{n}
\end{align*}

This suggests we use the proportion of successes out of our $n$ trials as our estimate for the true probability $p$.

This estimate $\hat{p}$ is also called the sample proportion $Y$ and in terms of random variables we would write
\[
\hat{p} = Y = \frac{X}{n} = \frac{1}{n}\sum_{i = 1}^{n}X_i
\]
so $Y$ is simply the proportion of successes in our set of Bernoulli trials of size $n$.

\textit{Note:
$\hat{p} = Y$ can also be considered as simply the mean of the $X_i$.}

\subsubsection{The Binomial Distribution}
\begin{definition}[The Binomial Distribution]
    A random variable $X$ has a binomial distribution with parameters $n$ and $p$ if $X$ has a discrete distribution for which the pmf is as follows:
    \[
    f\left(x \mmid n, p\right) = \begin{cases}
        \binom{n}{x}p ^ xq ^ {n - x} & \text{for } x = 0, 1, 2, \dotsc, n, \\
        0 & \text{otherwise}.
    \end{cases}
    \]
    Here $n$ must be a positive integer and $p$ must lie in the interval $0 \leq p \leq 1$.
    We write $X \sim \Bin(n, p)$.
    The Binomial distribution is of fundamental importance to us because of the following result:

    \textit{If the collection of random variables $X_1, \dotsc, X_n$ form $n$ Bernoulli trials with parameter $p$,
    and if $X = X_1 + \dotsi + X_n$ represents the sum of the successes,
    then $X$ has a binomial distribution with parameters $n$ and $p$.}
\end{definition}

When $X$ is viewed as the sum of $n$ Bernoulli trials,
we can find the expectation,
variance and moment generating function of the binomial distribution easily.
\begin{align*}
    \E(X) &= \sum_{i = 1}^{n}\E(X_i) = np, \\
    \Var(X) &= \sum_{i = 1}^{n}\Var(X_i) = npq = np(1 - p), \\
    \psi(t) &= \E(e ^ {tX}) = \prod_{i = 1}^{n}\E(e ^ {tX_i}) = (pe ^ t + q) ^ n.
\end{align*}
The above expectation and variance of $X$ are as usual calculated from a view point before $X$ is actually measured.

We can similarly understand our estimator $\hat{p} = Y = \frac{X}{n}$ of the probability $p$.



\textbf{Aside:
Normal approximation to Binomial and Continuity Correction}

We know $X \sim \Bin(n, p)$ but this is sometimes cumbersome to calculate probabilities with.
We can approximate the binomial distribution by a Normal distribution with the same mean and variance:
\[
\Bin(n, p)\text{ is approximately } N(np, np(1 - p))
\]
this approximation is acceptable when $np \geq 10$ and $n(1 - p) \geq 10$ and the larger these value the better.

For small $n$,
a continuity correction might be appropriate:

if $X \sim \Bin(n, p)$ and $X' \sim N(np, np(1 - p))$,
then
\begin{align*}
    \P(X \leq k) &\simeq \P(X' \leq k + 1 / 2) \\
    \P(k_1 \leq X \leq k_2) &\simeq \P(k_1 - 1 / 2 \leq X' \leq k_2 + 1 / 2)
\end{align*}

\subsection{The Sample Proportion as an Estimator for \texorpdfstring{$p$}{}}
As $X \sim \Bin(n, p)$ we have that
\begin{align*}
    \E(\hat{p}) = \E(Y) &= \E\left(\frac{X}{n}\right) = \frac{1}{n}\E(X) \\
    &= \frac{1}{n}np = p \\
    \Var(\hat{p}) = \Var(Y) &= \Var\left(\frac{X}{n}\right) = \frac{1}{n ^ 2}(X) \\
    &= \frac{1}{n ^ 2}npq = \frac{pq}{n} = \frac{p(1 - p)}{n}.
\end{align*}

We have that $\E(\hat{p}) = p$,
that is the expectation of our estimator $\hat{p}$ is equal to the thing we are trying to estimate.
We say the estimator is unbiased.

As we have $\Var(\hat{p}) = \frac{p(1 - p)}{n}$ we now have some understanding and some control over how accurate our estimate is:
if we double the size of the sample $n$ then the variance will decrease by $2$.
The corresponding standard deviation would only decrease by $\sqrt{2}$.

\textbf{Normal Approximation}

As $X \sim \Bin(n, p)$ and $Y = \frac{X}{n}$,
we can calculate probabilities for $Y = \hat{p}$
(if we are given $n$ and $p$ say),
but if $n$ is large this is cumbersome.

Instead we can employ the Normal approximation for $X$ and then $Y$:
\begin{align*}
    X &\sim \Bin(n, p) \\
    \implies X &\sim N(np, np(1 - p)) \\
\implies \hat{p} = Y &\sim N\left(p, \frac{p(1 - p)}{n}\right).
\end{align*}

\textbf{Margin of Error}

How accurate is our estimator $Y$?
The margin of error of an estimate can be roughly defined
(for now)
as two standard deviations $\mathrm{SD}(Y)$ on either side of the estimate,
suggesting the true value $p$ may lie in an interval of the form:
\[
Y \pm 2\sqrt{\frac{p(1 - p)}{n}}
\]
this is pretty useless since we don't know $p$,
if we did then there would be no point in estimating.

We can find a very useful upper bound on the margin of error:
\[
\max_{p \in [0, 1]}p(1 - p) = \frac{1}{4}\text{ at } p = \frac{1}{2}.
\]
Therefore,
\[
\text{Margin of Error } = 2\sqrt{\frac{p(1 - p)}{n}} \leq 2\sqrt{\frac{1}{4n}} = \frac{1}{\sqrt{n}}
\]
that is,
the margin of error is bounded by $\frac{1}{\sqrt{n}}$ no matter what the value of $p$.
So our suggested standard deviation interval becomes the famous result:
\[
Y \pm 2\sqrt{\frac{p(1 - p)}{n}} = Y \pm \frac{1}{\sqrt{n}}.
\]

\begin{example}
    $22$nd October $2024$,
    we are about to ask $1000$ people in our poll.
    
    Question $1$:
    Find the expected value and the margin of error for the proportion of Trump voters in our sample if we were told that
    \begin{enumerate}[label = (\alph*)]
        \item $p = 0.5$
        \item $p = 0.3$.
    \end{enumerate}
    
    \begin{solution}
        \begin{enumerate}[label = (\alph*)]
            \item
            $\E(X) = np = 1000 \times 0.5 = 500$.
    
            $\E(\hat{p}) = p = 0.5 = 50\%$.
    
            $\Var(X) = np(1 - p) = 1000 \times 0.5 \times 0.5 = 250$.
    
            $\mathrm{SD}(X) = 15.8$ people.

            \[
            \Var(\hat{p}) = \frac{p(1 - p)}{n} = \frac{0.5(0.5)}{1000} = 0.00025
            \]

            Margin of error $2\sqrt{\frac{p(1 - p)}{n}} = 2\sqrt{\frac{0.5 \times 0.5}{1000}} \approx 0.0316 = 3.16\%$.
            
            \item
            If $p = 0.3 \implies \E(\hat{p}) = 0.3$ and margin of error is $0.0290 = 2.90\%$.
        \end{enumerate}
    \end{solution}
\end{example}

\begin{example}
    Poll was performed $n = 1000$,
    $515$ for Trump $485$ for Harris.

    What is your estimate for $p$ and its margin or error?

    \begin{solution}
        We use $\hat{p}$ to estimate $p$:
        \[
        \hat{p} = \frac{x}{n} = \frac{515}{1000} = 0.515 = 51.5\%.
        \]
        We do not know $p$,
        so we use the maximum bound for the margin of error
        \[
        \frac{1}{\sqrt{n}} = \frac{1}{\sqrt{1000}} \approx 0.0316 = 3.16\%.
        \]
        So we thing $p$ will lie within:
        \[
        51.5\% \pm 3.16\%.
        \]

        \textit{Note that $50\%$ lies in this interval.}
    \end{solution}
\end{example}

\begin{example}
    Your company has time to perform one more poll before the election.
    How large a poll is needed to ensure a margin of error less than $1\%$?

    \begin{solution}
        Must have:
        \[
        \frac{1}{\sqrt{n}} < 0.01 \iff n > \frac{1}{0.01 ^ 2} \iff n > 10000.
        \]
    \end{solution}
\end{example}


We wanted $p$ and had data
\[
X_i = \frac{0 \text{ or } 1}{i = 1, \dotsc, n}
\]

Used estimator:
$\hat{p}$ as a guess.

$\hat{p}$ properties:
\begin{align*}
    \E(\hat{p}) &= p \\
    \Var(\hat{p}) &= \frac{p(1 - p)}{n} < \frac{1}{4n}.
\end{align*}

\textbf{Big question:}
Does this structure generalise e.g. $X_i \in \R$
(not just $0, 1$)
or where $X_i$ are generated from more complex distributions?

Answer:
Yes.

\section{The Frequentist Statistics Paradigm}

\subsection{Sampling,
Inference and the Sample Mean}

\textbf{Terminology:}

A population is a group of $N$ people or objects of interest.
Call the objects units or subjects.

A sample is the subset of the population that is examined.

Many ways to choose this sample.

A simple random sample
(SRS)
of size $n$.

A stratified random sample take a simple random sample from strata e.g. men,
women,
old,
young.

A quota sample.

A population parameter:
e.g. the mean of population $\mu$,
the variance of the population $\sigma ^ 2$
could be from a Normal distribution or more complex.
The probability $p$ of success in a binomial distribution.

We want to make inferences i.e. to learn about these population parameters.
A statistic is a number that is calculated from the sample data,
usually a summary:
e.g. the sample mean $\Bar{X}$ and the sample variance $s ^ 2$,
e.g. the sample proportion $Y = \hat{p}$.

The sampling distribution is the distribution of the statistic that describes how it can vary from sample to sample.

Statistics are often used as estimators of population parameters.
For example we saw $\hat{p} = Y$ which is the estimator for $p$.

We will be concerned with certain aspects of estimators:
whether or not they are biased e.g. if $\E(\text{estimator}) \overset{\neq}{=} \text{ population parameter}$,
degree of variability
(i.e. their variance).

\textbf{Randomisation:}
is the key weapon to ensure zero bias.

\textbf{Variability:}
is usually proportional to $(\text{sample size}) ^ {-1}$.

We can look at an estimator with:
high bias and high variance,
high bias and low variance,
low bias and high variance,
low bias and low variance.

\subsubsection{Inference}
Inference is the act of drawing conclusions from certain basic facts and premises.

The inferences we draw are rarely certain:
uncertainty is everywhere.

\subsubsection{The Sample Mean \texorpdfstring{$\Bar{X}$}{} as an Estimator for the Population Mean \texorpdfstring{$\mu$}{}}

We assume that:
there is a population of interest,
with mean value $\mu$ and standard deviation $\sigma$,
often both unknown.

Out main aim is to say something about $\mu$,
then our secondary aim is to say something about $\sigma$.
We would like to estimate $\mu$ with little or no bias and small variance,
so that our guess is on target and can be expected to be close.

We take a simple random sample of size $n$ from this population
(assume successive samples independent).
We will label the sample values $X_1, X_2, \dotsc, X_n$.

Each random variable having the same mean $\E(X_i) = \mu$ and standard deviation $\mathrm{SD}(X_i) = \sigma$ as the population.

We summarise that each $X_i$ is independent and has the same distribution,
expectation and variance by writing that $X_1, \dotsc, X_n$ are independent and identically distributed with mean $\mu$ and standard deviation $\sigma$.

We define the sample mean to be
\[
\Bar{X} = \frac{1}{n}\sum_{i = 1}^{n}X_i.
\]

\textbf{Derivation of properties of the sample mean $\Bar{X}$}
\begin{align*}
    \E(\Bar{X}) &= \E\left(\frac{1}{n}\sum_{i = 1}^{n}X_i\right) = \frac{1}{n}\E\left(\sum_{i = 1}^{n}X_i\right) = \frac{1}{n}\sum_{i = 1}^{n}\E(X_i) \\
    &= \frac{1}{n}\sum_{i = 1}^{n}\mu = \frac{1}{n}n\mu = \mu \\
    \Var(\Bar{X}) &= \Var\left(\frac{1}{n}\sum_{i = 1}^{n}X_i\right) = \frac{1}{n ^ 2}\Var\left(\sum_{i = 1}^{n}X_i\right) = \frac{1}{n ^ 2}\frac{1}{n}\sum_{i = 1}^{n}\Var(X_i) \\
    &= \frac{1}{n ^ 2}\sum_{i = 1}^{n}\sigma ^ 2 = \frac{1}{n ^ 2}n\sigma ^ 2 = \frac{\sigma ^ 2}{n}.
\end{align*}

Will the sample mean $\Bar{X}$ be a good estimator for the population mean $\mu$?

We say that $\Bar{X}$ is an unbiased estimator of $\mu$ since $\E(\Bar{X}) = \mu$.

$\Var(\Bar{X}) = \frac{\sigma ^ 2}{n}$ is understood,
and can be controlled by $n$,
but it is not unbounded:
it depends on the population variance $\sigma ^ 2$.

$\Bar{X}$ therefore has a smaller standard deviation than a single observation.

If the main population of $X$ is normally distributed with mean $\mu$ and standard deviation $\sigma$,
then the distribution of the sample mean is also Normal,
but now with $\Bar{X} \sim N(\mu, \sigma ^ 2 / n)$.

\begin{example}
    Consider the distribution of heights of US males aged $18$-$74$.
    The average height is about $69$ inches,
    with standard deviation about $3$ inches.

    Find the expectation and standard deviation of the sample mean from a simple random sample
    (SRS)
    of size $n = 25$ and $n = 50$.

    \begin{solution}
        $n = 25$
        \[
        \E(X) = 69 \implies \sigma = \frac{3}{\sqrt{25}} = \frac{3}{5}.
        \]

        $n = 50$
        \[
        \E(X) = 69 \implies \sigma = \frac{3}{\sqrt{50}} = \frac{3}{5\sqrt{2}}.
        \]
    \end{solution}
\end{example}

\subsection{The Central Limit Theorem}

\begin{theorem}[The Central Limit Theorem]
    Suppose $X_1, X_2, \dotsc, X_n$ are $n$ independent and identically distributed random variables,
    each with mean $\mu$ and variance $\sigma ^ 2$.

    The distribution of the sample mean $\Bar{X} = \frac{1}{n}\sum_{i}X_i$ of these random variables is such that
    \[
    \Bar{X} \rightarrow N\left(\mu, \frac{\sigma ^ 2}{n}\right) \text{ as } n \rightarrow \infty,
    \]
    regardless of the distribution of the $X_i$.
\end{theorem}

\begin{example}
    The number of flaws per square metre in a type of carpet is variable with mean $1.6$ flaws per square metre and standard deviation $1.2$ flaws per square metre.

    An inspector studies $200$ square metres of material,
    records the number of flaws found in each square metre,
    and calculates $\Bar{X}$,
    the mean number of flaws per square metre inspected.
    What is the probability that $\Bar{X}$ exceeds $1.7$ per square metre?

    \begin{solution}
        We have a random sample $X_1, \dotsc, X_{200}$,
        each with expectation $\E(X_i) = 1.6$ and $\Var(X_i) = 1.2 ^ 2$.
        By CLT
        \[
        \Bar{X} \sim N\left(1.6, \frac{1.2}{\sqrt{200}}\right) = N(1.6, 0.085 ^ 2).
        \]
        We seek the
        \[
        \P(\Bar{X} > 1.7) = \P\left(\frac{\Bar{X} - \mu}{\frac{\sigma}{\sqrt{n}}} > \frac{1.7 - \mu}{\frac{\sigma}{\sqrt{n}}}\right) = \P\left(Z > \frac{1.7 - 1.6}{0.085}\right) = \P(Z > 1.18).
        \]
        From the tables we see that the probability is $1 - 0.8810 = 0.1190$.
        Hence the probability that $\Bar{X}$ will exceed $1.7$ is $0.1190$.
    \end{solution}
\end{example}

\subsubsection{Standard Errors and the \texorpdfstring{$t$}{} Distribution}

The standard error of the sample mean,
if the individual $X_i \sim UK(\mu, \sigma ^ 2)$,
unknown distribution with mean $\mu$ and variance $\sigma ^ 2$,
the CLT tells us that the distribution of the sample mean is $\Bar{X} \sim N(\mu, \sigma ^ 2 / n)$ as $n \rightarrow \infty$.
However,
we need to know the population variance $\sigma ^ 2$ in order to use these results,
which we don't know.

What if the population standard deviation $\sigma$ is unknown,
and $n$ is large?

Estimate the population standard deviation $\sigma$ by the sample standard deviation,
which before the data is measured is the random variable $S$:
\[
S = \sqrt{\frac{1}{n - 1}\sum_{i = 1}^{n}(X_i - \Bar{X}) ^ 2} = \sqrt{\frac{1}{n - 1}\left(\sum_{i = 1}^{n}X_i ^ 2 - n\Bar{X} ^ 2\right)}
\]
and after the data is measured becomes just the real number $s$:
\[
s = \sqrt{\frac{1}{n - 1}\sum_{i = 1}^{n}(x_i - \Bar{x}) ^ 2} = \sqrt{\frac{1}{n - 1}\left(\sum_{i = 1}^{n}x_i ^ 2 - n\Bar{x} ^ 2\right)}.
\]
Under certain conditions we have $\E(S ^ 2) = \sigma ^ 2$,
and is hence an unbiased estimator
(the unbiased condition requires $\frac{1}{n - 1}$ instead of $\frac{1}{n}$).

We can estimate the standard deviation of the sample mean $\frac{\sigma}{\sqrt{n}}$ by the standard error of the sample mean,
$\frac{s}{\sqrt{n}}$.

Putting this standard error,
in the random variable form $\frac{S}{\sqrt{n}}$,
into the Central Limit Theorem,
we get the result
\[
\frac{\Bar{X} - \mu}{\frac{S}{\sqrt{n}}} \sim N(0, 1)
\]
if $n$ sufficiently large.

If $n$ is not sufficiently large then $s$ is a poor estimate for $\sigma$,
$\frac{\Bar{X} - \mu}{\frac{S}{\sqrt{n}}}$ is no longer Normally distributed.

\textit{In general,
we need $n \geq 30$ for these results to hold.}

\textbf{The $t$ Distribution}

What if the population standard deviation $\sigma$ is unknown and $n$ is small?

If the distribution of the $X_i$ is Normal then we can proceed as follows.
We still estimate $\sigma$ by $s$,
but now we use the $t$ distribution instead of the Normal distribution.

The sample mean then has the following distribution
\[
\frac{\Bar{X} - \mu}{\frac{S}{\sqrt{n}}} \sim t_{n - 1}
\]
and our sampling theory still holds.

\begin{definition}
    A random variable $T$ has a $t$ distribution with degrees of freedom parameter $\nu$ if it has continuous distribution with probability density function
    \[
    f\left(t\mmid v\right) = \frac{\Gamma\left(\frac{\nu + 1}{2}\right)}{\sqrt{\nu\pi}\Gamma\left(\frac{\nu}{2}\right)}\left(1 + \frac{t ^ 2}{\nu}\right) ^ {-\frac{v + 1}{2}}
    \]
    where the normalising factor employs the gamma function $\Gamma$,
    a continuous version of the factorial function,
    with $\Gamma(n) = (n - 1)!$ for positive integer $n$.
\end{definition}

We write that $T \sim t_{\nu}$,
and note that $\E(T) = 0$ and $\Var(T) = \frac{\nu}{\nu - 2}$ for $\nu > 2$,
($\infty$ or undefined otherwise).

Calculating directly using $f\left(t\mmid v\right)$ is difficult,
so we use pre-calculated tables,
just as for the Normal distribution.

The full definition of the Gamma function is
\[
\Gamma(z) = \int_{0}^{\infty}x ^ {z - 1}e ^ {-x}\,dx.
\]

\textbf{Properties of the $t$ Distribution}
\begin{enumerate}[label = (\roman*)]
    \item The $t_{n - 1}$ distribution has a similar shape to a standard normal $N(0, 1)$.

    \item The $t_{n - 1}$ has "fatter tails" - more probability is assigned to values farther from the centre and with the tails getting fatter as $n$ gets smaller.

    \item The $t_{n - 1}$ has variance greater than one,
    and is given by $\frac{n - 1}{n - 3}$ for $n \geq 4$ and $\infty$ otherwise
    (note we are using $\nu = n - 1$).
    It has greater spread than a standard normal random variable.

    \item $\liminfty t_{n - 1} = N(0, 1)$,
    so it converges towards the normal distribution as $n$ gets larger.

    \item If $n \geq 15$ we can test whether our data is normally distributed via a normal quantile plot:
    use of the $t_{n - 1}$ distribution here requires the original population to be
    (approximately)
    normally distributed.
\end{enumerate}

\begin{example}
    A lightbulb manufacturer claims that the mean life of a lightbulb is $1200$ hours.
    A consumer association randomly selects $16$ bulbs,
    with the intention of rejecting the manufacturers claim if the sample mean $\Bar{X}$ is less than $1160$ hours.
    The sample standard deviation is $s = 200$.

    If the manufacturers are,
    in fact,
    honest,
    what is the probability that they will be declared dishonest?
    Find a value $c$ so that the probability that the lightbulb sample mean is smaller than $c$ is $0.05$.

    \begin{solution}
        By our theory,
        the distribution of the standardised sample mean is
        \[
        T = \frac{\Bar{X} - \mu}{\frac{S}{\sqrt{n}}} = \frac{\Bar{X} - 1200}{\frac{200}{\sqrt{16}}} \sim t_{15}.
        \]
        Now,
        the probability that this sample mean is smaller than $1160$ is
        \begin{align*}
            \P(\Bar{X} < 1160) &= \P\left(\frac{\Bar{X} - 1200}{\frac{200}{\sqrt{16}}} < \frac{1160 - 1200}{\frac{200}{\sqrt{16}}}\right) \\
            &= \P(T < -0.8), & T \sim t_{15} \\
            &= \P(T > 0.8), &(\text{By symmetry})
        \end{align*}
        Examining the tables of the $t$ distribution with $15$ degrees of freedom,
        we see that $\P(T > 0.691) = 0.25$ and $\P(T > 0.866) = 0.20$,
        so the probability we require is somewhere between $0.20$ and $0.25$.

        The $t$ distribution is most often used in reverse,
        as follows.

        Find a value $c$ so that the probability that the lightbulb sample mean is smaller than $c$ is,
        say,
        $0.05$,
        i.e. $\P(\Bar{X} < c) = 0.05$.
        For $15$ degrees of freedom,
        the $t$ table shows us that $\P(T < -1.753) = \P(T > 1.753) = 0.05$.
        Therefore $\P\left(\frac{\Bar{X} - 1200}{\frac{200}{\sqrt{16}}} < -1.753\right) = 0.05$.
        Rearranging shows us that $\P(\Bar{X} < 1200 - 50(1.753)) = 0.05$,
        i.e. $\P(\Bar{X} < 1112.35) = 0.05$.
        Thus,
        if the consumer association want to accuse the manufacturers of dishonest with probability $5\%$ of being wrong,
        their threshold under these circumstances should be $1112.35$.
    \end{solution}
\end{example}

\subsection{Confidence Intervals}
\subsubsection{Inference about \texorpdfstring{$\mu$}{}}

Suppose we take a simple random sample,
$X_1, \dotsc, X_n$ from our population with mean $\mu$ and variance $\sigma ^ 2$.

The central limit theorem implies that $\Bar{X} \sim Nl\left(\mu, \frac{\sigma ^ 2}{n}\right)$,
if $n > 20$ then it is good.

Since we know the distribution of $\Bar{X}$ we can make probability statements about $\Bar{X}$,
e.g. $\P(\Bar{X} > A)$.

E.g.
from our normal tables
($Z \sim N(0, 1)$):
\[
\P(-1.96 \leq Z \leq 1.96) = 0.95 \implies \P\left(-1.96 \leq \frac{\Bar{X} - \mu}{\frac{\sigma}{\sqrt{n}}} \leq 1.96\right) = 0.95.
\]
But this is the wrong way around as we are interested in $\mu$ not $\Bar{X}$.
So,
we can rearrange to get $\mu$ in the middle:
\[
\P\left(\Bar{X} - 1.96\frac{\sigma}{\sqrt{n}} \leq \mu \leq \Bar{X} + 1.96\frac{\sigma}{\sqrt{n}}\right)
\]
\[
\mu \in \left[\Bar{X} - 1.96\frac{\sigma}{\sqrt{n}}, \Bar{X} + 1.96\frac{\sigma}{\sqrt{n}}\right]
\]
with probability $0.95$.
Note:
this is a random interval and as $\Bar{X}$ is still random until we observe it,
we still cannot use this to learn about $\mu$ yet.

\subsubsection{Confidence Intervals:
Definition}
Suppose we actually observe a particular random sample:
\[
X_1 = x_1, X_2 = x_2, \dotsc, X_n = x_n.
\]
We can now substitute $\Bar{x} = \frac{1}{n}\sum_{i = 1}^{n}x_i$ into our random interval to construct a confidence interval for $\mu$:
\[
\mu \in \left[\Bar{x} - 1.96\frac{\sigma}{\sqrt{n}}, \Bar{x} + 1.96\frac{\sigma}{\sqrt{n}}\right]
\]
we call this a $95\%$ confidence interval as the theoretical probability statement from which it is derived had probability $0.95$.

\textbf{Important:}
A confidence interval is not a probability statement.
It is the realisation of a random interval.
Once it is observed,
it is no longer random.

$\mu$ is not a random variable.

Note the following \textbf{important} statement
\[
\P\left(\Bar{x} - 1.96\frac{\sigma}{\sqrt{n}} \leq \mu \leq \Bar{x} + 1.96\frac{\sigma}{\sqrt{n}}\right) \neq 0.95.
\]

\subsubsection{Confidence Intervals for the Population Mean \texorpdfstring{$\mu$}{}}

$\sigma$ known.

We have a simple random sample $X_1, \dotsc, X_n$.
The population standard deviation $\sigma$ is known.

Either:
\begin{enumerate}[label = \alph*)]
    \item We know the population is normal.

    \item $n$ is large
    ($n \geq 20$)
    so we can safely use CLT.
\end{enumerate}
We calculated the observed sample mean $\bar{x}$.
Then a $(1 - \alpha)\%$ confidence interval for $\mu$ is:
\[
\bar{x} \pm z ^ {*}\frac{\sigma}{\sqrt{n}}
\]
where $z ^ {*}$ is called a critical value of a standard normal random variable $z$ such that:
\[
\P(-z ^ {*} \leq Z \leq z ^ {*}) = 1 - \alpha
\]
where $Z \sim N(0, 1)$.

\textbf{$\sigma$ unknown,
$n$ small,
population normal $N(0, 1)$}

Same setup but:
$\sigma$ is unknown,
$n$ is small.
We know the population is Normal,
we calculate $\bar{x}$ and $s$
(sample standard deviation).
Then a $(1 - \alpha)\%$ confidence interval is
\[
\bar{x} \pm t_{n - 1} ^ {*}\frac{s}{\sqrt{n}}
\]
where $t_{n - 1} ^ {*}$ is a critical value such that:
\[
\P(-t_{n - 1} ^ {*} \leq T \leq t_{n - 1} ^ {*}) = 1 - \alpha
\]
where $T \sim t_{n - 1}$.

E.g.
if $\alpha = 0.05$ and $n = 11$ this implies $t_{10} ^ {*} = 2.228$ from the table.

\textbf{$\sigma$ unknown,
$n$ large}

Setup is the same as before.
$\sigma$ is unknown,
$n$ is large,
say $n \geq 30$.
We calculate $\Bar{x}$ and now $s$ is an accurate estimate for $\sigma$.
Then a $(1 - \alpha)\%$ confidence interval for $\mu$ is
\[
\bar{x} \pm z ^ {*}\frac{s}{\sqrt{n}}
\]
$z ^ {*}$ the same as before.

\begin{example}[Candle lifetimes]
    A candle making process makes candles with varying lifetimes $X_i$,
    with $\sigma ^ 2 = 0.4$.
    Lifetimes are known to be Normally distributed.
    The mean lifetimes $\mu$ is unknown.
    Sample of $n = 6$,
    \[
    8.1, 8.7, 9.7, 7.8, 8.4, 9.4
    \]
    hours.

    Find a $99\%$ confidence interval for $\mu$.

    \begin{solution}
        We calculate:
        $\Bar{x} = 8.6, n = 6$ population normally distributed implies
        \[
        \Bar{x} = N\left(\mu, \frac{\sigma ^ 2}{n}\right).
        \]
        $99\%$ confidence interval implies $\alpha = 0.01$.
        $z ^ {*}$ with $0.5\%$ to the right on a normal table is $z ^ {*} = 2.575$ which implies $99\%$ confidence interval is:
        \begin{align*}
            \Bar{x} \pm z ^ {*}\frac{\sigma}{\sqrt{n}} &= 8.6 \pm 2.575 \cdot \frac{\sqrt{0.4}}{\sqrt{6}} \\
            &= [7.94, 9.26].
        \end{align*}
    \end{solution}
\end{example}

\textbf{$\sigma$ unknown,
$n$ small,
Normal}

Suppose that,
we have a simple random sample $X_1, \dotsc, X_n$,
the population standard deviation $\sigma$ is unknown,
we know the population is normal,
$n$ is small,
we calculated the observed sample mean $\Bar{x}$,
and the observed sample standard deviation $s$.

Then a $(1 - \alpha)\%$ confidence interval for $\mu$ is
\[
\Bar{x} \pm t_{n - 1}^{*}\frac{s}{\sqrt{n}}
\]
where $t_{n - 1}^{*}$ is the critical value of a $t$ distributed random variable with $(n - 1)$ degrees of freedom such that
\[
\P(-t_{n - 1}^{*} \leq T \leq t_{n - 1}^{*}) = 1 - \alpha.
\]
For example,
we see $\alpha = 0.05$ and $n = 11$ gives $t_{10}^{*} = 2.228$ from the $t$-table.

\textbf{Normal Quantile Plots}:
We draw a normal quantile plot by ordering the $n$ data values $x_1, \dotsc, x_n$ from smallest to largest,
plotting these ordered values against the $n$ quantiles $z_k$ that satisfy $\Phi(z_k) = \frac{k}{n + 1}$,
$k = 1, \dotsc, n$,
where $\Phi(x)$ is the normal cumulative distribution function,
that we get from the normal table.
If the plotted points form roughly a straight line we conclude there is no evidence against normality.

\begin{example}[Iron Retention in Mice]
    An experiment was performed to determine how well a particular form of iron ($\text{Fe} ^ {3+}$) is retained in the body.
    The investigators gave $\text{Fe} ^ {3+}$ to $18$ mice.
    The percentage of iron retained is listed for each mouse below.
    \begin{table}[H]
        \begin{tabular}{cccccccccc}
             $\text{Fe} ^ {3+}$ & $2.20$ & $2.93$ & $3.08$ & $3.49$ & $4.11$ & $4.95$ & $5.16$ & $5.54$ & $5.68$ \\
             \phantom{} &  $6.25$ & $7.25$ & $7.90$ & $8.85$ & $11.96$ & $15.54$ & $15.89$ & $18.30$ & $18.59$
        \end{tabular}
    \end{table}

    $\Bar{x} = 8.20$ and $s = 5.45$.
    Obtain a $90\%$ confidence interval for the population mean for the $\text{Fe} ^ {3+}$ data.
    $\sigma$ is unknown,
    so first check for Normality of the data:
    draw a boxplot and a normal quantile plot.

    \begin{solution}
        A boxplot isn't that hard to draw so we will not draw it.

        For our Iron Retention in Mice data we have $n = 18$ and the largest data value is $18.59$ which we plot against $z_{18}$ which satisfies $\Phi(z_{18}) = \frac{18}{18 + 1} \simeq 0.947$.
        From the normal table we see that $z_{18} \simeq 1.62$ and we hence plot the point with coordinates $(1.62, 18.59)$.
        Doing this for all ordered points gives the following table,
        \begin{table}[H]
            \begin{tabular}{|c|ccccccccc|}
                \hline
                $k$ & $1$ & $2$ & $3$ & $4$ & $5$ & $6$ & $7$ & $8$ & $9$ \\
                \hline
                 Ordered data $x_k$ & $2.20$ & $2.93$ & $3.08$ & $3.49$ & $4.11$ & $4.95$ & $5.16$ & $5.54$ & $5.68$ \\
                 $\Phi(z_k) = \frac{k}{n + 1}$ & $0.0526$ & $0.105$ & $0.158$ & $0.211$ & $0.263$ & $0.316$ & $0.368$ & $0.421$ & $0.474$ \\
                 Quantiles $z_k$ & $-1.62$ & $-1.25$ & $-1.00$ & $-0.80$ & $-0.63$ & $-0.48$ & $-0.34$ & $-0.20$ & $-0.07$ \\
                \hline
                $k$ & $10$ & $11$ & $12$ & $13$ & $14$ & $15$ & $16$ & $17$ & $18$ \\
                \hline
                 Ordered data $x_k$ &  $6.25$ & $7.25$ & $7.90$ & $8.85$ & $11.96$ & $15.54$ & $15.89$ & $18.30$ & $18.59$ \\
                 $\Phi(z_k) = \frac{k}{n + 1}$ & $0.526$ & $0.579$ & $0.632$ & $0.684$ & $0.737$ & $0.789$ & $0.842$ & $0.895$ & $0.947$ \\
                 Quantiles $z_k$ & $0.07$ & $0.20$ & $0.34$ & $0.48$ & $0.63$ & $0.80$ & $1.00$ & $1.25$ & $1.62$ \\
                 \hline
            \end{tabular}
        \end{table}
        then plot the $x_k$ against $z_k$.

        The normal quantile plot is curved,
        so it is not approximately a straight line,
        so the data doesn't look normal.

        The sample size is only $18$,
        so CLT plus direct estimate of $\sigma$ by $s$ does not apply.

        If we take logs then the quantile plot is approximately normal.
        $n$ is small and data appears to be normal so we can construct a confidence interval using $t$-distribution,
        so we have:
        $\bar{x} \pm t_{n - 1}^{*}\frac{s}{\sqrt{n}}$.
        We want a $90\%$ confidence interval,
        so find the critical value from $t$ tables with $\alpha = 0.1$.
        $t_{17}^{*} = 1.740$
        (from $t_{17}$ table with $5\%$ probability to right of $t_{17}^{*}$).
        So the confidence interval is $\bar{x} \pm t_{n - 1}^{*}\frac{s}{\sqrt{n}} = 1.90 \pm 1.740 \times 0.66 / \sqrt{18} = [1.63, 2.17]$.
    \end{solution}
\end{example}

\textbf{$\sigma$ unknown,
$n$ large}

Suppose that we have a simple random sample $X_1, \dotsc, X_n$,
the population standard deviation $\sigma$ is unknown,
the sample is large,
$n \geq 30$,
we calculated the observed sample mean $\bar{x}$,
and the observed sample standard deviation $s$.

Then a $(1 - \alpha)\%$ confidence interval for $\mu$ is
\[
\bar{x} \pm z ^ {*}\frac{s}{\sqrt{n}}
\]
where $z ^ {*}$ is the critical value of the standard normal random variable such that
\[
\P(-z ^ {*} \leq Z \leq z ^ {*}) = 1 - \alpha.
\]

\textbf{Summary}

We have seen the following cases:

$\sigma$ is known,
$n$ is large,
or population is normal
\[
\bar{x} \pm z ^ {*}\frac{\sigma}{\sqrt{n}}.
\]
$\sigma$ is unknown:

$n$ is small and the population is normal
\[
\bar{x} \pm t_{n - 1}^{*}\frac{s}{\sqrt{n}}
\]
$n$ is large
\[
\bar{x} \pm z ^ {*}\frac{s}{\sqrt{n}}.
\]
If we don't find ourselves in any of these cases,
we need to use alternative methods
(e.g. non-parametric methods).


\subsubsection{Margin of Error}
Most of our confidence intervals have the form
\begin{align*}
    \bar{x} &\pm \frac{c}{\sqrt{n}} \\
    \text{Estimate}&\pm\text{Margin of error}
\end{align*}
The value of the margin of error is an indication of the inaccuracy of the estimate at this level of confidence.
The large $n$,
the smaller the margin of error.

\begin{example}[Margin of Error for Candle Data]
    The candle data,
    we know that $\sigma = \sqrt{0.4}$.
    Hence the margin of error for a $95\%$ confidence interval would be
    \[
    \frac{1.96\sqrt{0.4}}{\sqrt{n}}.
    \]
    suppose we want to find $n$ such that the margin of error is $\pm 0.1$.
    \begin{solution}
        \begin{align*}
            \frac{1.96\sqrt{0.4}}{\sqrt{n}} &= 0.1 \\
            \frac{1.96\sqrt{0.4}}{0.1} &= \sqrt{n} \\
            153.7 &= n.
        \end{align*}
        Hence we need a sample of about $154$ candles to give a $95\%$ confidence interval with a margin of error of $\pm 0.1$.
    \end{solution}
\end{example}

\subsection{Hypothesis Testing}

\subsubsection{Introduction}
A way to test a hypothesis about a $\mu$ is to construct a confidence interval for $\mu$.
If the hypothesised value is contained within the confidence interval,
the data supports the hypothesis,
otherwise,
the data does not support the hypothesis.

\textbf{Terminology}

Suppose we are interested in a single unknown population parameter $\theta$,
e.g. the mean $\mu$ of a population,
or the population standard deviation $\sigma$.

We have a number $r$ which we either believe may be the value for $\theta$,
or is a value against which we wish to compare $\theta$.

\begin{definition}[Null and Alternative Hypotheses]
    $H_0$ is the null hypothesis,
    $H_0$ generally hypothesises that $\theta$ is equal to some value $r$.

    $H_a$ is the alternative hypothesis,
    $H_a$ denies the null hypothesis,
    the type of denial determines whether it is a two or one sided test.

    A two-sided hypothesis test is stated as
    \begin{align*}
        H_0 : \theta &= r \\
        H_a : \theta &\neq r.
    \end{align*}

    The one-sided hypothesis test is stated as either of these two combinations:
    \begin{align*}
        H_0 : \theta &= r & H_0 : \theta &= r \\
        H_a : \theta &< r & H_a : \theta &> r.
    \end{align*}
\end{definition}

\begin{example}
    Let $\mu$ be the mean of the population of cuckoo egg lengths.
    An ornithologist wishes to test the hypothesis that $\mu = 22.5$.

    \begin{solution}
        The two sided test:
        \begin{align*}
            H_0 : \mu &= 22.5 \\
            H_a : \mu &\neq 22.5
        \end{align*}
    \end{solution}
\end{example}

\subsubsection{Hypothesis Testing via Confidence Intervals}
\textbf{Two-sided case}

If we have,
a two-sided hypothesis,
$H_0 : \theta = r$,
$H_a : \theta \neq r$.
An estimator for $\theta$,
the sampling distribution of the estimator
(as a function of $\theta$),
and a level of significance $\alpha$.

We can then construct a $1 - \alpha$ confidence interval for $\theta$,
and then we can do one of the following things
\begin{enumerate}[label = (\roman*)]
    \item Reject $H_0$ if $r$ lies outside the confidence interval,
    and find the test statistically significant at the $\alpha\%$ level of significance.

    \item Fail to reject $H_0$ otherwise and find the test not significant at the $\alpha\%$ level of significance.
\end{enumerate}

\textbf{One-sided case}

If we have:
a one-sided hypothesis:
$H_0 : \theta = r$,
$H_a : \theta < r$
(or $H_a : \theta > r$).
An estimator for $\theta$,
the sampling distribution of the estimator
(as a function of $\theta$),
a level of significance $\alpha$.

We can then construct a $1 - 2\alpha$ confidence interval for $\theta$,
and then we can do one of the following things
\begin{enumerate}[label = (\roman*)]
    \item Reject $H_0$ if $r$ falls to the right
    (left)
    of the confidence interval.

    \item Fail to reject $H_0$ otherwise.
\end{enumerate}

\begin{example}[Candle Lifetimes]
    For the earlier example of candle lifetimes,
    let $H_0 : \mu = 9.2$ and $H_a : \mu \neq 9.2$.
    Should we reject $H_0$ or not,
    at $1\%$ significance level?

    \begin{solution}
        Significance level $\alpha = 1\%$ implies $1 - \alpha = 99\%$ confidence interval as seen, $n$ small,
        normally distributed,
        $\sigma$ known,
        so the confidence interval is given by
        \[
        \bar{x} \pm z ^ {*}\frac{\sigma}{\sqrt{n}} = 8.6 \pm 2.575 \times \frac{\sqrt{0.4}}{\sqrt{6}} = [7.94, 9.26]
        \]
        $99\%$ confidence interval contains $\mu = 9.2$ therefore we:
        fail to reject $H_0$ at the $1\%$ significance level.
    \end{solution}
\end{example}

\begin{example}[Nicotine]
     To test whether the mean nicotine content of a brand of cigarettes is the advertised value of $1.4$mg,
     a health group takes a random sample of $n = 80$ cigarettes,
     with $\bar{x} = 1.5$,
     $s = 0.3$.

     Consider a two sided test,
     $H_0 : \mu = 1.4$,
     $H_a : \mu \neq 1.4$.
     Would they reject $H_0$ at the $10\%$ significance level,
     or not?

     \begin{solution}
         $n$ is large which means we can use a normal approximation,
         $\sigma \simeq s$,
         and the $90\%$ confidence interval for $\mu$ is
         \[
         \bar{x} \pm z ^ {*}\frac{s}{\sqrt{n}} = 1.5 \pm 1.645\frac{0.3}{\sqrt{80}} = [1.44, 1.56]
         \]
         which does not contain $\mu = 1.4$ therefore we:
         reject $H_0$ at the $10\%$ significance level.
     \end{solution}
\end{example}

\subsubsection{Hypothesis Testing via \texorpdfstring{$p$}{}-Values}
\textbf{Method}:

\begin{definition}[$p$-value]
    Calculating confidence intervals is one way to test a hypothesis,
    alternatively we can calculate an appropriate test statistic from the data.
    We can then work out the probability of observing a value at least as extreme as the statistic under the assumption that $H_0$ is true.
    This probability is known as the $p$-value.
\end{definition}

We can find the $p$-value by comparing the value of the statistic with critical values of the relevant sampling distribution.

The more extreme the statistic,
the more unlikely it is that the assumptions of $H_0$ are true.
I.e.,
small $p$-value implies we reject $H_0$.

The threshold for $p$-value is the significance level $\alpha$.

A typical test statistic,
for testing the population mean,
is the
(standardised)
sample mean.

\begin{example}
    Again,
    for the earlier example of candle lifetimes,
    let $H_0 : \mu = 9.2$ and $H_a : \mu \neq 9.2$.
    Find the $p$-value.
    Should we reject $H_0$ or not?

    \begin{solution}
        $n$ is small,
        normally distributed and $\sigma$ is known.

        Under $H_0$,
        i.e. assuming $H_0$ is true,
        $\mu = 9.2$,
        so $\bar{X} \sim N(9.2, 0.4 / 6)$.

        Hence we get our $p$-value:
        \begin{align*}
            p\text{-value} &= \text{probability of observing $\bar{X}$ at least as extreme as $\bar{x} = 8.6$,
            given $H_0$} \\
            &= \P(\bar{X} \leq 8.6) + \P(\bar{X} \geq 9.8) \\
            &= 2\P(\bar{X} \geq 9.8)\qquad (\text{by symmetry about } \mu = 9.2) \\
            &= 2\P\left(\frac{\bar{X} - 9.2}{\sqrt{\frac{0.4}{6}}}\geq \frac{9.8 - 9.2}{\sqrt{\frac{0.4}{6}}}\right)\qquad (\text{using $\mu = 9.2$ given $H_0$}) \\
            &= 2\P\left(Z \geq \frac{9.8 - 9.2}{\sqrt{\frac{0.4}{6}}}\right) \\
            &= 2\P(Z \geq 2.32) \\
            &= 2(1 - \P(Z \leq 2.32)) \\
            &= 2(1 - 0.9898) = 0.0204.
        \end{align*}
        Therefore,
        as the $p\text{-value} < 0.05$,
        we reject $H_0$ at the $5\%$ significance level.

        However,
        we would fail to reject $H_0$ at the $1\%$ significance level.
    \end{solution}
\end{example}

\subsubsection{Case Summary}
Given $H_0 : \mu = \mu_0$ and $H_a : \mu \neq \mu_0$,
we have the following:
\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c|c}
         $\sigma$ & $n$ & sampling & confidence interval & test statistic for $p$-value  \\
         \hline
         known & large & any & $\bar{x} \pm z ^ {*}\frac{\sigma}{\sqrt{n}}$ & $\frac{\bar{X} - \mu_0}{\sigma / \sqrt{n}} \sim N(0, 1)$ \\
         known & small & normal & $\bar{x} \pm z ^ {*}\frac{\sigma}{\sqrt{n}}$ & $\frac{\bar{X} - \mu_0}{\sigma / \sqrt{n}} \sim N(0, 1)$ \\
         unknown & large & any & $\bar{x} \pm z ^ {*}\frac{s}{\sqrt{n}}$ & $\frac{\bar{X} - \mu_0}{S / \sqrt{n}} \sim N(0, 1)$ \\
         unknown & small & normal & $\bar{x} \pm t_{n - 1}^{*}\frac{s}{\sqrt{n}}$ & $\frac{\bar{X} - \mu_0}{S / \sqrt{n}} \sim t_{n - 1}$
    \end{tabular}
\end{table}

\subsubsection{Terminology Summary}
There are two "flows" a test can follow,
they go as follows:

Observed standardised sample mean in tail of distribution,
test statistic extreme,
reject $H_0$,
hypothesised value outside $(100 - \alpha)\%$ confidence interval,
test is significant at $\alpha\%$.

Observed standardised sample mean in middle of distribution,
test statistic not extreme,
fail to reject $H_0$,
hypothesised value inside $(100 - \alpha)\%$ confidence interval,
test is not significant at $\alpha\%$.

\subsubsection{Errors in Hypothesis Tests}
There are two kinds of errors in hypothesis testing:

\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c}
         & $H_0$ true & $H_0$ false \\
         \hline
         Fail to reject $H_0$ & Correct decision & Type $II$ error \\
         Reject $H_0$ & Type $I$ error & Correct decision
    \end{tabular}
\end{table}

\begin{remark}
    Type $I$ and type $II$ errors are similar to false positive and false negatives.
\end{remark}

\begin{definition}[Significance and Power of a test]
    All hypothesis tests have two related properties.
    The first is:
    \[
    \text{Significance level $\alpha$} = \cP{\text{Type $I$ error}}{H_0}.
    \]
    A low significance level is desirable.

    The second is:
    \[
    \text{Power of the test} = 1 - \cP{\text{Type $II$ error}}{H_a}.
    \]
    A high power is desirable.
\end{definition}

As we expect about $1$ in every $20$ of a set of independently constructed $95\%$ confidence intervals not to contain $\mu$,
so too do we expect mistakenly to reject $H_0$ in about $1$ in every $20$ hypothesis tests at the $5\%$ level,
given that $H_0$ was actually true.

For example,
the number of type $I$ errors in $n$ independent experiments where we carry out a hypothesis test at a $10\%$ level of significance is distributed $\Bin(n, 0.1)$,
again,
given that $H_0$ was actually true in each case.

The significance and power are similar to false positives and false negatives as we saw when doing disease testing.

\subsubsection{Dangers of Significance Tests}
Why would we fail to reject a hypothesis at $5.01\%$ and yet reject at $5\%$,
the significance levels dichotomise the test procedure arbitrarily,
when in fact the degree of support for a hypothesis has hardly changed.

\subsubsection{Are Hypothesis Tests Meaningful?}
Looking at the prosecutor's fallacy with $E$ representing evidence and $G$ representing guilt.
Suspect is guilty if $\cP{E}{G ^ c}$ is small.
This is wrong we should actually calculate $\cP{G}{E}$.

We see a similar pattern for $p$-values and hypothesis tests:
We reject $H_0$ if $p$-value is small
\[
p\text{-value} = \cP{\text{sample mean is at least as extreme as the one observed}}{H_0\text{ is true}}
\]
this is also wrong,
we should calculate
\[
\cP{\text{$H_0$ is true}}{\text{sample mean}}.
\]

\subsection{Inference for a Proportion}

\subsubsection{Normal Approximation}
Consider a binomially distributed random variable $X$ with parameters $n$ and $p$
\[
X \sim \Bin(n, p)
\]
The population proportion $p$ is unknown,
it is to be estimated from data.
The sample proportion $\hat{p} = Y = X / n$ can be used as an estimator for $p$ for example if we take a simple random sample of $1000$ adults and find that the number of men is $483$,
our estimate of the proportion of men in the UK adult population would be $y = 483 / 1000 = 0.483$.
Denoting $Y$ the sample proportion,
instead of $\hat{p}$ allows us to represent the observed sample proportion as $y$.

We have
\begin{align*}
    \E(Y) &= p \\
    \Var(Y) &= \frac{p(1 - p)}{n}
\end{align*}
so that means,
the estimator $Y$ is unbiased,
the variance of the estimator gets smaller as $n$ increases.

\textbf{Issue $1$}:
$p$ is unknown,
so $\Var(Y)$ is also unknown
(although we can bound it to $\Var(Y) < \frac{1}{4n}$).
$n$ is large which implies $\Var(Y) \simeq \frac{y(1 - y)}{n}$,
where $y$ is the observed sample proportion.

\textbf{Issue $2$}:
The sampling distribution of $Y$ is hard to calculate.
If $np \geq 10$ and $n(1 - p) \geq 10$ then the normal approximation is valid.

With these two issues solved,
we write:
\[
Y \sim N(p, \Var(Y)),\text{ or equivalently } \frac{Y - p}{\sqrt{\Var(Y)}} \sim N(0, 1),\text{ with } \Var(Y) \simeq \frac{y(1 - y)}{n}.
\]

Given the sampling distribution for $Y$,
and the observed proportion $y$ we can do hypothesis testing and construct confidence intervals for $p$.

The $1 - \alpha$ confidence interval for $p$ is:
\[
y \pm z ^ {*}\sqrt{\frac{y(1 - y)}{n}}
\]
with $z ^ {*}$ such that $\P(-z ^ {*} \leq Z \leq z ^ {*}) = 1 - \alpha$ for $Z \sim N(0, 1)$.

The $p$-value for the hypothesis test $H_0 : p = p_0$ vs $H_a : p \neq p_0$ is given by:
\[
p\text{-value} = 2\left[1 - \P\left(Z < \frac{|y - p_0|}{\sqrt{\frac{y(1 - y)}{n}}}\right)\right],\quad\text{with } Z \sim N(0, 1).
\]
\begin{proof}[Proof for $p$-value for proportions]
    \begin{align*}
        p\text{-value for proportions} &= \text{Probability $Y$ is as extreme as $y$,
        given $H_0 : p = p_0$ is true} \\
        &= \P(Y \leq p_0 - \delta) + \P(Y \geq p_0 + \delta)\qquad(\text{with $\delta = |y - p_0|$}) \\
        &= 2\P(Y \geq p_0 + \delta)\ (\text{by symmetry of approximating norm dist}) \\
        &= 2\P\left(\frac{Y - p_0}{\sqrt{\frac{y(1 - y)}{n}}} \geq \frac{\delta}{\sqrt{\frac{y(1 - y)}{n}}}\right) \\
        &= 2\P\left(Z \geq \frac{\delta}{\sqrt{\frac{y(1 - y)}{n}}}\right) \\
        &= 2\left[1 - \P\left(Z \leq \frac{\delta}{\sqrt{\frac{y(1 - y)}{n}}}\right)\right] \\
        &= 2\left[1 - \P\left(Z \leq \frac{|y - p_0|}{\sqrt{\frac{y(1 - y)}{n}}}\right)\right]\qquad(\text{replacing $\delta = |y - p_0|$}).
    \end{align*}
\end{proof}

\subsubsection{Better Approximations}
It has been shown that the $1 - \alpha$ confidence interval given above is not that reliable.
In the long run,
generally,
it contains the population parameter $p$ at a rate far less than $1 - \alpha$.

Consequently,
the normal approximation can be a very poor approximation,
particularly for extreme values of $p$ and low $n$.

More detailed calculations yield improved confidence intervals for $p$.
For example:

\textbf{The Wilson Interval}
\[
\frac{y + \frac{t}{2}}{1 + t} \pm \frac{\sqrt{y(1 - y)t + \frac{t ^ 2}{4}}}{1 + t},\ \text{with } t = \frac{(z ^ {*}) ^ 2}{n}.
\]
\textbf{The Agresti-Coull Interval}
\[
\tilde{y} \pm z ^ {*}\sqrt{\frac{\tilde{y}(1 - \tilde{y})}{\tilde{n}}}\text{ with } \tilde{y} = \frac{ny + 2}{n + 4} \text{ and } \tilde{n} = n + 4.
\]

\subsubsection{Examples of Confidence Intervals and \texorpdfstring{$p$}{} for Proportions}

\begin{example}[Drop out rates at U.K. Universities]
    Suppose we want to estimate the first year drop out rate $p$ across the country and take a simple random sample of size $n = 250$ and see $28$ students failed to continue beyond first year.

    Calculate standard $95\%$ confidence interval for $p$,
    and the Wilson $95\%$ confidence interval.

    \begin{solution}
        We have $y = \frac{x}{n} = \frac{28}{250} = 0.112$.
        \[
        y \pm z ^ {*}\sqrt{\frac{y(1 - y)}{n}} = 0.112 \pm 1.96\sqrt{\frac{0.112 \cdot 0.588}{250}} = [0.073, 0.151].
        \]

        Wilson interval:
        $t = \frac{(z ^ {*}) ^ 2}{n} = \frac{1.96 ^ 2}{250} = 0.0154$,
        Wilson $95\%$ confidence interval:
        \[
        \frac{y + \frac{t}{2}}{1 + t} \pm \frac{\sqrt{y(1 - y)t + \frac{t ^ 2}{4}}}{1 + t} = [0.079, 0.157].
        \]
    \end{solution}
\end{example}

\newpage

\section{The Likelihood}

\subsection{Introduction and Definition}

We imagine that we will gather data $X_i$ with $i = 1, 2, \dotsc, n$.
Now we may not know the precise distribution that generated this data ,
but we may suspect that the distribution is one of a family of possible distributions,
labelled or parametrised by a parameter $\theta$
($\theta$ could even represent a list of parameters).

We saw this when we were discussing Bernoulli trials with $X_i \sim \mathrm{Bernoulli}(p)$ here $\theta = p$.

We also saw this when we were looking at $X_i \sim N(\mu, \sigma ^ 2)$,
here $\theta = \{\mu, \sigma ^ 2\}$.

The joint probability density function
(or probability mass function if $X_i$ are discrete)
of the data is simply represented as
\[
f(x_1, x_2, \dotsc, x_n\mid\theta).
\]
However,
once we measure the data:
\[
X_1 = x_1, X_2 = x_2, \dotsc, X_n = x_n
\]
This joint probability density function can now be viewed as just a function of $\theta$ as the data are now fixed.

\begin{definition}[The likelihood function]
    Suppose we have $X_1, \dotsc X_n$ that have joint probability density function $f(x_1, \dotsc, x_n\mid \theta)$ the likelihood function $\ell(\theta)$,
    is just the probability density function of the observed data considered as a function of $\theta$ only i.e.
    \[
    \ell(\theta) \equiv \ell(\theta; x_1, \dotsc, x_n) = f(x_1, \dotsc, x_n\mid \theta)
    \]
    and the $\log$-likelihood function is:
    \[
    \mathcal{L}(\theta) \equiv \log(\ell(\theta)) = \log(f(x_1, \dotsc, x_n\mid \theta)).
    \]
\end{definition}

\begin{definition}[Likelihood for independently identically distributed data]
    If the $X_i$ are independent and identically distributed then the expression for the likelihood takes a more pleasant form.

    Suppose each $X_i$ has a probability density function given by $f(x_i\mid\theta)$ and that all $X_i$ are independent and identically distributed then:
    \[
    \ell(\theta) = f(x_1, \dotsc, x_n\mid\theta) = \prod_{i = 1}^{n}f(x_i\mid\theta)
    \]
    and the $\log$-likelihood:
    \[
    \mathcal{L}(\theta) = \log(f(x_1, \dotsc, x_n\mid\theta) = \log{\prod_{i = 1}^{n}f(x_i\mid\theta)} = \sum_{i = 1}^{n}\log(f(x_i\mid\theta)).
    \]
\end{definition}

Note $\ell(\theta)$ is not a probability density function with respect to $\theta$,
as $\theta$ is just a fixed but unknown parameter
(at this point),
so $\ell(\theta)$ will not integrate to one with respect to $\theta$.
However,
$\ell(\theta)$ is still useful as it shows us which values of $\theta$ are more 'likely' to have generated the data.
E.g.
we saw its use in Bernoulli Trials.

\begin{example}[Likelihood for Bernoulli Trials]
    In the case of $n$ Bernoulli trials we had independent identically distributed $X_i \sim \mathrm{Bernoulli}(p)$ so $X_i$ discrete and equal $1$ or $0$ with probability $p$ or $(1 - p) = q$.
    Hence
    \[
    f(x_i\mid p) = \begin{cases}
        p ^ {x_i}q ^ {1 - x_i} & \text{for } x_i = 0, 1 \\
        0 & \text{otherwise}.
    \end{cases}
    \]
    Here our parameter of interest is $\theta = p$ so we write our likelihood as $\ell(p)$ instead of $\ell(\theta)$.
    \[
    \ell(p) = f(x_1, \dotsc, x_n\mid p) = \prod_{i = 1}^{n}f(x_i\mid p) = \prod_{i = 1}^{n}p ^ {x_i}q ^ {1 - x_i} = p ^ {\sum_{i = 1}^{n}x_i}q ^ {\sum_{i = 1}^{n}(1 - x_i)} = p ^ xq ^ {n - x},
    \]
    $x = \sum_{i = 1}^{n}x_i$.
    The $\log$-likelihood:
    \[
    \mathcal{L}(p) = \log f(x_1, \dotsc, x_n\mid p) = \log(p ^ xq ^ {n - x}) = x\log{p} + (n - x)\log\underbrace{(1 - p)}_{= q}.
    \]
    We then maximised this to find an estimator for $p$
    (more of this soon).
\end{example}

\begin{example}[Likelihood for the Binomial Scenario]
    In a Binomial scenario we have that $X$ is the sum or count of the successes from $n$ Bernoulli trials with parameter $p$,
    this implies $X \sim \Bin(n, p)$.

    When viewed in this Binomial framework,
    we have one single experiment,
    that yields the realisation $X = x$.

    Hence,
    due to a single experiment the likelihood is simply
    ($n$ is known):
    \[
    \ell(p) = f(x\mid p) = \binom{n}{x}p ^ xq ^ {n - x}
    \]
    and the $\log$-likelihood:
    \[
    \mathcal{L}(p) = \log{f(x\mid p)} = \log\left[\binom{n}{x}p ^ xq ^ {n - x}\right] = \log\left(\frac{n!}{(n - x)!x!}\right) + x\log{p} + (n - x)\log\underbrace{(1 - p)}_{= q}.
    \]
\end{example}

\begin{example}[Likelihood for the Poisson Distribution]
    The Poisson distribution is often used to model radioactive decay counts and a wide range of other phenomena
    (e.g. traffic,
    queuing).

    If the data has Poisson distribution we say $X_i \sim \Po(\lambda)$ where $\lambda$ is the parameter of interest
    (it actually equals the expected number of counts so $\E(X_i) = \lambda$).

    \begin{solution}
        Poisson distribution:
        \[
        f(x_i \mid \lambda) = \begin{cases}
            \frac{e ^ {-\lambda}\lambda ^ {x_i}}{x_i!} &\text{for } x_i = 0, 1, 2, \dotsc \\
            0 &\text{otherwise}.
        \end{cases}
        \]
        Therefore the likelihood of $n$ independent and identically distributed data values $X_i = x_i$ is:
        \[
        \ell(\lambda) = f(x_1, \dotsc, x_n\mid \lambda) = \prod_{i = 1}^{n}f(x_i\mid \lambda) = \prod_{i = 1}^{n}\frac{e ^ {-\lambda}\lambda ^ {x_i}}{x_i!} = \frac{e ^ {-n\lambda}\lambda ^ {\sum_{i = 1}^{n}x_i}}{\prod_{i = 1}^{n}x_i!}.
        \]
        The $\log$-likelihood:
        \[
        \mathcal{L}(\lambda) = \log{f(x_1, \dotsc, x_n\mid \lambda)} = \log\left(\frac{e ^ {-n\lambda}\lambda ^ {\sum_{i = 1}^{n}x_i}}{\prod_{i = 1}^{n}x_i!}\right) = -n\lambda + \left(\sum_{i = 1}^{n}x_i\right)\log{\lambda} - \log\left(\prod_{i = 1}^{n}x_i!\right).
        \]
    \end{solution}
\end{example}

\subsection{Maximum Likelihood Estimation}
This is useful for many reasons,
it gives us a way to find good estimators of $\theta$.
This procedure is known as Maximum Likelihood Estimation:
we just find the value of $\theta$ that maximises $\ell(\theta)$ for the given sample $x_1, \dotsc, x_n$,
we typically denote this as $\hat{\theta}_{MLE}$
(Maximum Likelihood Estimator)

\begin{definition}[Maximum Likelihood Estimator]
    \[
    \hat{\theta}_{MLE} \equiv \mathrm{argmax}_{\theta}\,\ell(\theta) = \mathrm{argmax}_{\theta}\,\mathcal{L}(\theta).
    \]
\end{definition}
Note that the $\hat{\theta}_{MLE}$ maximises both $\ell(\theta)$ and $\mathcal{L}(\theta)$ as $\log$ is a monotonic transform
(so it cannot change the location of the maximum).

This is a general technique.
As we can find $\hat{\theta}_{MLE}$ for general data $x_1, \dotsc, x_n$ we consider it a full estimator.

In general maximal likelihood estimators have good properties,
especially for large $n$,
but note that they are not always unbiased.

\begin{example}[Maximum Likelihood Estimator for Bernoulli Trials]
    For Bernoulli trials:
    \[
    \mathcal{L}(p) \equiv x\log{p} + (n - x)\log(1 - p)
    \]
    and we already found:
    \[
    \pd[\mathcal{L}(p)]{p} = \frac{x}{p} - \frac{(n - x)}{(1 - p)} = 0
    \]
    this is equivalent to $\hat{p}_{MLE} = \frac{x}{n}$.

    Note that to ensure that this is a maximum we should also check the second derivative:
    \[
    \frac{\partial ^ 2\mathcal{L}(p)}{\partial p ^ 2} = -\frac{x}{p ^ 2} - \frac{(n - x)}{(1 - p) ^ 2} < 0
    \]
    therefore $\hat{p}_{MLE}$ is at a maximum!
\end{example}

\begin{example}[Maximum Likelihood Estimator for Binomial Scenario]
    For Binomial Scenario:
    \[
    \mathcal{L}(p) = \log\binom{n}{x} + x\log{p} + (n - x)\log(1 - p)
    \]
    which implies
    \[
    \pd[\mathcal{L}(p)]{p} = 0 + \frac{x}{p} - \frac{(n - x)}{(1 - p)} = 0
    \]
    which implies $\hat{p}_{MLE} = \frac{x}{n}$.

    Already checked second derivative in previous example.
    We can check if this estimator $\hat{p}_{MLE}$ is unbiased:
    \[
    \E(\hat{p}_{MLE}) = p.
    \]
\end{example}

\begin{example}[Maximum Likelihood Estimator for Poisson Scenario]
    For the identically independently distributed Poisson data where $X_i \sim \Po(\lambda)$:
    \[
    \mathcal{L}(\lambda) = -n\lambda + \left(\sum_{i = 1}^{n}x_i\right)\log{\lambda} - \log\left(\prod_{i = 1}^{n}x_i!\right).
    \]
    To find the maximum likelihood estimator $\hat{\lambda}_{MLE}$ for $\lambda$,
    we just partially differentiate with respect to $\lambda$:
    \[
    \pd[\mathcal{L}(\lambda)]{\lambda} = -n + \left(\sum_{i = 1}^{n}x_i\right)\frac{1}{\lambda} - 0 = 0
    \]
    this is equivalent to
    \[
    \frac{\left(\sum_{i = 1}^{n}x_i\right)}{\hat{\lambda}_{MLE}} = n \iff \hat{\lambda}_{MLE} = \frac{1}{n}\sum_{i = 1}^{n}x_i = \bar{x}.
    \]
    Before the data is measured we can view the general maximum likelihood estimate as $\hat{\lambda}_{MLE} = \frac{1}{n}\sum_{i = 1}^{n}X_i = \bar{X}$.

    Therefore
    \[
    \E(\hat{\lambda}_{MLE}) = \E\left(\frac{1}{n}\sum_{i = 1}^{n}X_i\right) = \frac{1}{n}\sum_{i = 1}^{n}\E(X_i) = \frac{1}{n}\sum_{i = 1}^{n}\lambda = \frac{1}{n}(n\lambda) = \lambda
    \]
    thus $\hat{\lambda}_{MLE}$ is unbiased.
\end{example}

\subsection{Sufficiency}

\begin{definition}[Sufficiency]
    If we have a sample of data $x_1, \dotsc, x_n$,
    a statistic $T(x_1, \dotsc, x_n)$ is said to be sufficient for $\theta$ if any only if we can factorise the likelihood $\ell(\theta)$ in the following form:
    \[
    \ell(\theta) = f(x_1, \dotsc, x_n\mid\theta) = g(T, \theta)h(x_1, \dotsc, x_n)
    \]
    where we see that all the $\theta$ behaviour of the likelihood is tied together with $T$ through the function $g(T, \theta)$,
    but the extra behaviour of $h(x_1, \dotsc, x_n)$ that contains additional details of the data,
    is essentially irrelevant.

    Therefore,
    a sufficient statistic $T$ contains all of the information about the parameter $\theta$ that we can extract from the sample $x_1, \dotsc, x_n$.

    The above definition generalises to the case where $T$ represents a vector of sufficient statistics.
\end{definition}

\begin{example}[Sufficiency for Binomial Scenario]
    For the Binomial Scenario we had likelihood
    \[
    \ell(p) = f(x\mid p) = \binom{n}{x}p ^ x(1 - p) ^ {n - x}
    \]
    which can be written inn the form of the Factorisation theorem as
    \[
    \ell(p) = g(x, p)h(x_1, \dotsc, x_n)
    \]
    with $g(x, p) = p ^ x(1 - p) ^ {n - x}$ and $h(x_1, \dotsc, x_n) = \binom{n}{x}$.

    Hence $T = x$ is the sufficient statistic for our parameter of interest $\theta = p$ as before,
    again assuming we also know $n$.
\end{example}

\newpage

\section{The Bayesian Statistics Paradigm}

\textbf{Fundamental Principle of Bayesian Statistics}

Everything that is uncertain can be treated as random and be associated with its own probability distribution,
provided we use a subjective interpretation of probability.


Following this subjective approach,
we treat the parameter $\theta$ as a random variable.
Its uncertainty is described by a
(subjective)
pdf $f(\theta)$.
The likelihood of the data $\ell(\theta)$ now can be fully viewed as the conditional probability distribution,
$f(x\mid\theta)$,
of the data given by the parameter.

\textbf{Fundamental Procedure of Bayesian Statistics}

The problem of "learning about $\theta$ from the data" then becomes trivial:
use conditional probability with $f(\theta)$ and $f(x\mid\theta)$ to find $f(\theta\mid x)$,
which is the conditional pdf of the parameter $\theta$ given the data $x$.
Thus we use the rules of probability
(i.e. Bayes Theorem)
to learn about our parameter from the data.

\subsection{Bayesian Statistics}

\textbf{Prior}:
We have a collection of possible parameter values represented by $\theta$ for a statistical model,
(or a collection of potential statistical models,
or a combination of both)
which could describe the future data,
$X$.
We assign a prior distribution,
$f(\theta)$ over the possible parameter values or models,
which expresses our uncertainty about the value of the parameter or the appropriate statistical model,
$\theta$,
before we see any data.
This is often based on scientific insight,
consideration of previous data/observations,
and logic.

\textbf{Data}:
We observe the data,
$X = x$.
Having observed $x$,
we can now formulate the likelihood,
$f(x\mid\theta)$,
of seeing the data given the model or parameter value $\theta$.
This is the same as the standard likelihood $\ell(\theta)$ through the meaning is quite different.
In the Bayesian approach $\theta$ is a random variable,
so $f(x\mid\theta)$ is the conditional distribution of $x$ given $\theta$.
In the frequentist approach,
$\theta$ is not a random variable,
so $\ell(\theta)$ is not treated as a density and is instead just a function returning the density of $x$ for different parameter values.

\textbf{Posterior}:
After seeing the data,
we evaluate the likelihood of each parameter value or statistical model $\theta$ given the data $x$,
and apply Bayes theorem to obtain posterior probabilities for each of the different parameter values or models.
Thus we obtain the posterior distribution,
$f(\theta\mid x)$,
of parameter
(or model)
$\theta$,
which expresses our uncertainty about the value of the parameter value or statistical model $\theta$ given the information we have learned after we have seen the data.

\textbf{Inference}:
Using the posterior distribution,
$f(\theta\mid x)$,
the problem of inference becomes one of making statements about the posterior distributions,
such as probability intervals,
point estimates,
or assessments of the probability of particular hypotheses.


\textbf{Fundamental Equation of Bayesian Statistics:
The Posterior}

Any Bayesian statistical problem can then be simply expressed as
\[
f(\theta\mid x) = \frac{f(x\mid\theta)f(\theta)}{f(x)},
\]
or in words,
using the terminology above
\[
\text{Posterior} = \frac{\text{Likelihood} \times \text{Prior}}{\text{Data probability}}.
\]







































\end{document}